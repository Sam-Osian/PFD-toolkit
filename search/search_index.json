{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#background","title":"Background","text":"<p>PFD Toolkit is an open-source Python package created to transform how researchers, policymakers, and analysts accessed and analysed Prevention of Future Death (PFD) reports from coroners in England and Wales.</p>"},{"location":"#the-problem","title":"The problem","text":"<p>PFD reports have long served as urgent public warnings \u2014 issued when coroners identified risks that could, if ignored, lead to further deaths. Yet despite being freely available, these reports were chronically underused. This was for one simple reason: they were a nightmare to work with. Common issues included:</p> <ul> <li> <p>No straightforward way to download reports in bulk</p> </li> <li> <p>Wildly inconsistent formats, making traditional web scraping unreliable</p> </li> <li> <p>No system for surfacing recurring themes</p> </li> <li> <p>Widespread miscategorisation of reports, creating research limitations</p> </li> <li> <p>No easy way for users to screen reports for cases relevant to their research</p> </li> </ul> <p>As a result, valuable insights often ended up buried beneath months or even years of manual admin. Researchers were forced to sift through thousands of reports one by one, wrestle with patchy metadata, and code themes by hand. </p>"},{"location":"#our-solution","title":"Our solution","text":"<p>PFD Toolkit acts as a one-stop-shop for extracting, screening and analysing PFD report data.</p> <p>The package brings together every PFD report and made them available in a single, downloadable dataset, ready for instant analysis. This dataset looks like this:</p> url id date coroner area receiver investigation circumstances concerns https://www.judiciary.uk/prevention... 2025-0207 2025-04-30 Alison Mutch Manchester South Flixton Road... On 1st October... Louise Danielle... During the course... https://www.judiciary.uk/prevention... 2025-0208 2025-04-30 Joanne Andrews West Sussex... West Sussex County... On 02 November... Mrs Turner drove... During the course... https://www.judiciary.uk/prevention... 2025-0120 2025-04-25 Mary Hassell Inner North London The President... On 23 August... Jan was a big baby... During the course... https://www.judiciary.uk/prevention... 2025-0206 2025-04-25 Jonathan Heath North Yorkshire and York Townhead Surgery On 04 June... On 15 March 2024... During the course... https://www.judiciary.uk/prevention... 2025-0199 2025-04-24 Samantha Goward Norfolk The Department... On 22 August... In summary, on... During the course... <p>As of the latest update, PFD Toolkit includes 5720 PFD reports.</p> <p>PFD Toolkit was built to break down every major barrier to PFD report analysis. Out of the box, you can:</p> <ol> <li> <p>Load live PFD data in seconds</p> </li> <li> <p>Query and filter reports with natural language</p> </li> <li> <p>Summarise reports to highlight key messages</p> </li> <li> <p>Automatically discover recurring themes</p> </li> <li> <p>Tag and organise reports based on these themes (or provide your own themes!)</p> </li> </ol> <p>Data is updated once a week, with newly published reports added to the toolkit.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install PFD Toolkit using pip:</p> <pre><code>pip install pfd_toolkit\n</code></pre>"},{"location":"#contribute","title":"Contribute","text":"<p>PFD Toolkit is designed as a research-enabling tool, and we\u2019re keen to work with the community to make sure it genuinely meets your needs. If you have feedback, ideas, or want to get involved, head to our Feedback &amp; contributions page.</p>"},{"location":"changelog/","title":"\ud83d\udcc6 Changelog","text":"<p>Welcome to the project changelog. All notable changes to this project will be documented below.</p>"},{"location":"changelog/#030-2025-07-01","title":"0.3.0 - 2025-07-01","text":"<p>First public release! \u2728</p>"},{"location":"contribute/","title":"Feedback &amp; contributions","text":"<p>Thank you for your interest in contributing to PFD Toolkit! We welcome input from researchers, data scientists, developers, and anyone passionate about improving access to coroners\u2019 Prevention of Future Death (PFD) reports.</p>"},{"location":"contribute/#how-you-can-get-involved","title":"How you can get involved","text":""},{"location":"contribute/#report-issues-bugs","title":"Report issues &amp; bugs \ud83d\udc1b","text":"<p>If you encounter a bug, data problem, or unexpected behaviour, please open an issue on Github.</p> <p>Include a clear description, steps to reproduce (if possible), and your Python version or environment details.</p>"},{"location":"contribute/#suggest-features-or-improvements","title":"Suggest features or improvements \ud83d\udca1","text":"<p>Have an idea for a new feature, a better workflow, or an additional data cleaning/categorisation option?</p> <p>Submit a feature request as a GitHub issue with as much detail as possible.</p>"},{"location":"contribute/#code-contributions","title":"Code contributions \ud83e\uddd1\u200d\ud83d\udcbb","text":"<p>Contributions are welcome - whether fixing bugs, adding new features, improving documentation, or expanding tests.</p> <p>Please fork the repository, create a new branch for your work, and submit a pull request with a clear description of your changes.</p> <p>If your change is significant, consider opening an issue first to discuss it.</p>"},{"location":"contribute/#local-setup","title":"Local setup","text":"<p>PFD Toolkit uses <code>uv</code> as its dependency management tool. Once <code>uv</code> is running on your system, install dependencies with:</p> <pre><code>uv sync\n</code></pre> <p>Run the test suite with:</p> <pre><code>uv run pytest\n</code></pre>"},{"location":"contribute/#anything-else-get-in-touch","title":"Anything else, get in touch \ud83d\udcac","text":"<p>If you have any questions, feedback or would like to contribute in a way not outlined above, please contact Sam on samoand@liverpool.ac.uk.</p>"},{"location":"llm_setup/","title":"Creating an LLM Client","text":"<p>PFD Toolkit uses a Large Language Model (LLM) client for advanced features. This page explains why you might need an LLM, how to set it up, and what you should know about API keys and costs.</p>"},{"location":"llm_setup/#why-do-i-need-an-llm-client","title":"Why do I need an LLM client?","text":"<p>Many toolkit features \u2014 like advanced cleaning, screening reports, and assigning themes \u2014 depend on AI. These tasks aren\u2019t reliable (or sometimes possible) with rule-based scripts alone.</p> <p>To use these features, you\u2019ll need to create an LLM client and pass it to the <code>Screener</code>, <code>Cleaner</code>, <code>Scraper</code>, or <code>Categoriser</code> objects. You do not need an LLM client to simply load report data (with <code>load_reports</code>).</p> <p>We appreciate that not everyone using this package will have worked with API keys before, so we've made setup extra simple.</p>"},{"location":"llm_setup/#setting-up-your-llm-client","title":"Setting up your LLM client","text":"<p>Import the <code>LLM</code> class and provide your API key (see below for details):</p> <pre><code>from pfd_toolkit import LLM\n\nllm_client = LLM(api_key=YOUR-API-KEY) # Replace YOUR-API-KEY with actual API key\n</code></pre> <p>And that's it \u2014 you can now use LLM-powered features! For example, to screen for reports about medication purchased online:</p> <pre><code>from pfd_toolkit import Screener\n\nquery = \"Deaths that followed ordering medication(s) online.\"\n\nscreener = Screener(llm=llm_client, # Assign llm client here\n                        reports = reports)\n\nonline_med_reports = screener.screen_reports(user_query=query)\n</code></pre>"},{"location":"llm_setup/#added-security","title":"Added security","text":"<p>It's important to never share your API key. This means making sure you don't commit your key to GitHub or similar services.</p> <p>For added security, we recommend storing your API in a <code>.env</code> file (e.g. <code>api.env</code>) and importing it through <code>load_dotenv</code>. For example:</p> <pre><code># In your .env file (never commit this to GitHub!)\nOPENAI_API_KEY=YOUR-API-KEY\n</code></pre> <p>Then, load the key in your script:</p> <pre><code>from dotenv import load_dotenv\nimport os\nfrom pfd_toolkit import LLM\n\nload_dotenv(\"api.env\")\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\n\nllm_client = LLM(api_key=openai_api_key)\n</code></pre>"},{"location":"llm_setup/#what-is-an-api-key","title":"What is an API key?","text":"<p>All LLM features in PFD Toolkit use OpenAI\u2019s servers. An API key is like a secret code that identifies you to OpenAI.</p> <p>You pay OpenAI for usage, not PFD Toolkit. The toolkit is free and open source. See OpenAI pricing for more \u2014 costs are based on tokens used (roughly, 1 word \u2248 1 token).</p>"},{"location":"llm_setup/#how-do-i-get-an-openai-api-key","title":"How do I get an OpenAI API key?","text":"<ol> <li>Sign up or login at OpenAI Platform.</li> <li>Go to API Keys.</li> <li>Click \"Create new secret key\", and copy the string.</li> <li>Store this somewhere safe. Never share your API key or commit it to public code.</li> <li>Add credit to your account (just $5 goes a long way for most research use).</li> </ol>"},{"location":"llm_setup/#advanced-options","title":"Advanced options","text":""},{"location":"llm_setup/#speed-up-your-llm","title":"Speed up your LLM","text":"<p>The LLM client supports parallelisation via the <code>max_workers</code> parameter. This controls the number of concurrent tasks the LLM can complete at once (each row/report is its own 'task'). For most workflows, set <code>max_workers</code> between 10-30.</p> <pre><code>llm_client = LLM(\n    api_key=openai_api_key,\n    max_workers=30      # &lt;--- increase parallelisation\n)\n</code></pre> <p>OpenAI does impose rate limits, however, so setting <code>max_workers</code> to an extremely high value may result in errors or slowdowns. </p> <p>PFD Toolkit tries to handle rate limit errors by briefly pausing the script once a rate limit has been exceeded. However, it's still good practice to set the parameter to a reasonable value to avoid errors.</p>"},{"location":"llm_setup/#change-the-model","title":"Change the model","text":"<p>By default, the LLM client will use <code>gpt-4.1-mini</code>. Our testing found that this offered the best balance between cost, speed and accuracy. However, you can change this to any supported OpenAI model.</p> <pre><code>llm_client = LLM(\n    api_key=openai_api_key,\n    model=\"o4-mini\"     # &lt;--- change model to o4-mini\n)\n</code></pre>"},{"location":"llm_setup/#use-a-custom-endpoint","title":"Use a custom endpoint","text":"<p>You can redirect the LLM to any custom endpoint (e.g. Azure, OpenRouter), provided they support the OpenAI SDK.</p> <pre><code>llm_client = LLM(\n    api_key=openai_api_key,\n    base_url=\"https://...\",   # &lt;--- Set custom endpoints\n)\n</code></pre>"},{"location":"non_coders/","title":"For Non-Coders","text":"<p>We appreciate that not all researchers are Python coders, and we also believe that this shouldn't stop you from unlocking the insights contained within PFD reports.</p> <p>If you have a research question, policy project, or just curiosity about PFD reports, please get in touch with me (Sam).</p>"},{"location":"non_coders/#how-i-can-help","title":"How I can help","text":"<p>If you want to use the PFD Toolkit but are not sure where to start, or you find the technical side a bit daunting, I am genuinely very happy to help. Here is what I can offer:</p> <ul> <li>Explain PFD reports. I can tell you more about what kind of information is contained within PFD reports and whether they could support your research or policy goals.</li> <li>Custom Scripts. Tell me what you are trying to do, for example, \"I want all reports related to mental health in the North West from 2022,\" or \"Can I get a table of reports mentioning medication errors?\" I can then write the script for you.</li> <li>Ready-to-Use Results. I will run the toolkit for you and provide you with the outputs you need, whether it is a spreadsheet, a summary, or visualisations.</li> <li>Ongoing Support. If you want to learn how to do it yourself next time, I can guide you at your pace.</li> </ul>"},{"location":"non_coders/#how-to-get-in-touch","title":"How to get in touch","text":"<p>Just reach out via email or LinkedIn.</p> <p>I want the toolkit to be useful to as many people as possible, not just programmers. If you are a policy worker, academic, journalist, campaigner, or someone affected by PFD reports, please reach out. I would be delighted to help you get the most out of this resource.</p>"},{"location":"pfd_reports/","title":"More about PFD reports","text":"<p>Prevention of Future Death (PFD) reports are a unique, under-recognised mechanism within the English and Welsh legal system for flagging hazards that threaten lives. These documents, written by coroners at the close of certain inquests, have the potential to drive real change \u2014 but only if their warnings are heard and acted upon.</p>"},{"location":"pfd_reports/#what-is-a-pfd-report","title":"What is a PFD report?","text":"<p>When a coroner concludes an inquest and believes that action should be taken to prevent future deaths, they are legally obliged (under Regulation 28 of the Coroners (Investigations) Regulations 2013) to issue a PFD report. The report is sent to any person or organisation the coroner thinks could take action. This could be an NHS trust, a regulator, a private company, a local council, or even the government.</p> <p>The aim is simple: to prevent further deaths by highlighting systemic risks, missed opportunities, or patterns of harm that have already claimed a life.</p>"},{"location":"pfd_reports/#what-do-pfd-reports-look-like","title":"What do PFD reports look like?","text":"<p>PFD reports tend to be short, factual documents. They usually contain:</p> <ul> <li> <p>The coroner\u2019s name and area</p> </li> <li> <p>The date of the reports</p> </li> <li> <p>The recipient(s) of the report</p> </li> <li> <p>Key details of the inquest</p> </li> <li> <p>The circumstances behind the death</p> </li> <li> <p>The coroner's concerns, explaining what went wrong and why further action is needed</p> </li> </ul> <p>These coroner concerns are the heart of PFD reporting. Between them, they contain a plethora of information on why so many deaths in England and Wales are preventable.</p> <p>But formatting varies wildly. Some reports are rich with detail; others are extremely brief. Some are typed, some are scanned PDFs, and some have inconsistent metadata or missing information. Some are correctly tagged with a broad category, while others are not for no clear reason.</p> <p>This variability is a big part of why working with PFDs at scale has been so difficult.</p>"},{"location":"pfd_reports/#why-do-pfd-reports-matter","title":"Why do PFD reports matter?","text":"<p>PFD reports offer us a rare window into risks and failures that may not appear in routine data. They can expose themes including, but not limited to:</p> <ul> <li> <p>Missed diagnoses and medical errors</p> </li> <li> <p>Gaps in mental health or social care provision</p> </li> <li> <p>Unsafe systems or environments (e.g. railway safety, housing, road design)</p> </li> <li> <p>Inadequate policies or regulatory oversight</p> </li> </ul> <p>Because coroners have a statutory duty to write them, PFD reports sometimes identify entirely new risks \u2014 before they turn into trends. For researchers and policymakers, they are a critical early-warning system.</p>"},{"location":"pfd_reports/#how-does-pfd-toolkit-help","title":"How does PFD Toolkit help?","text":"<p>PFD Toolkit addresses these barriers by automatically gathering, cleaning, and structuring every available PFD report \u2014 making them accessible, searchable, and ready for analysis at scale.</p>"},{"location":"usage/","title":"Getting started","text":"<p>This page talks you through an example workflow using PFD Toolkit. It doesn't cover everything: for more, take a look at the various pages on the top panel.</p>"},{"location":"usage/#installation","title":"Installation","text":"<p>PFD Toolkit can be installed from pip as <code>pfd_toolkit</code>:</p> <pre><code>pip install pfd_toolkit\n</code></pre>"},{"location":"usage/#load-your-first-dataset","title":"Load your first dataset","text":"<p>The quickest way to get started is by loading a pre-processed dataset. These datasets are updated weekly, meaning you always have access to the latest reports with minimal setup.</p> <pre><code>from pfd_toolkit import load_reports\nimport pandas as pd\n\n# Load 'all' PFD reports from April 2025\nreports = load_reports(\n    category = 'all', \n    start_date = \"2025-04-01\",\n    end_date = \"2025-04-30\")\n\n# Preview reports\nreports.head()\n</code></pre> <p><code>load_reports</code> will output a pandas DataFrame:</p> URL ID Date CoronerName Area Receiver InvestigationAndInquest CircumstancesOfDeath MattersOfConcern https://www.judiciary.uk/prevention... 2025-0207 2025-04-30 Alison Mutch Manchester South Flixton Road... On 1st October... Louise Danielle... During the course... https://www.judiciary.uk/prevention... 2025-0208 2025-04-30 Joanne Andrews West Sussex... West Sussex County... On 02 November... Mrs Turner drove... During the course... https://www.judiciary.uk/prevention... 2025-0120 2025-04-25 Mary Hassell Inner North London The President... On 23 August... Jan was a big baby... During the course... https://www.judiciary.uk/prevention... 2025-0206 2025-04-25 Jonathan Heath North Yorkshire and York Townhead Surgery On 04 June... On 15 March 2024... During the course... https://www.judiciary.uk/prevention... 2025-0199 2025-04-24 Samantha Goward Norfolk The Department... On 22 August... In summary, on... During the course..."},{"location":"usage/#screen-for-relevant-reports","title":"Screen for relevant reports","text":"<p>PFD Toolkit lets you query reports in plain English \u2014 no need to know precise keywords or categories. Just describe the cases you care about, and the toolkit will return matching reports.</p>"},{"location":"usage/#set-up-an-llm-client","title":"Set up an LLM client","text":"<p>Screening and other advanced features use AI models and require you to first set up an LLM client.</p> <pre><code>from pfd_toolkit import LLM\n\n# Set up LLM client\nllm_client = LLM(api_key=YOUR-API-KEY) # Replace with actual API key\n</code></pre>"},{"location":"usage/#screen-reports-in-plain-english","title":"Screen reports in plain English","text":"<p>Suppose you want to screen for reports based on a description, such as:</p> <p>\"Deaths that occurred in police custody\"</p> <p>PFD Toolkit's <code>Screener</code> allows you to submit this as a user query, returning relevant reports. You don't have to worry too much about you phrase this user query, as long as it's clear, concise and makes sense.</p> <pre><code>from pfd_toolkit import Screener\n\n# Create a user query to filter reports\nuser_query = \"Deaths that occurred in police custody\"\n\n# Set up the screening/filtering engine\nscreener = Screener(llm = llm_client,\n                        reports = reports, # Reports that you loaded earlier\n                        )\n\n# And screen/filter reports!\nfiltered_reports = screener.screen_reports(user_query=user_query)\n</code></pre> <p><code>filtered_reports</code> also returns a pandas DataFrame, but only contains reports that matched your query.</p> <p>For more information on Screening reports, see Screening relevant reports.</p>"},{"location":"usage/#what-next","title":"What next?","text":"<p>Once you've got your filtered dataset, it is ready for qualitative analysis tasks.</p> <p>You can do this manually, if you'd like, or you can use PFD Toolkit's Extractor module to surface key information from report, including recurring themes.</p>"},{"location":"extractor/","title":"Analysing PFD reports","text":"<p>PFD Toolkit ships with an <code>Extractor</code> class to pull \"features\" (i.e. key pieces of information) from Prevention of Future Death (PFD) reports. </p> <p>These features could be recurring themes, or more specific bits of information (e.g. age, sex, cause of death, etc.).</p> <p>The guides below walk through the main features:</p> <ul> <li>Basic usage \u2013 create a basic feature model to identify features from report data.</li> <li>Summaries &amp; token counts \u2013 generate short summaries and estimate the token cost of your data.</li> <li>Tagging reports with themes \u2013 automatically discover recurring themes or label reports with your own taxonomy.</li> <li>Capturing text spans \u2013 keep short excerpts (\"spans\") showing where each feature came from.</li> <li>Caching and exporting results \u2013 reuse completions to save time and API costs.</li> </ul>"},{"location":"extractor/basics/","title":"Basic usage","text":"<p>Start by defining a feature model with <code>pydantic</code>. Each attribute represents a piece of information you want to pull out of the report. <code>Extractor</code> accepts any valid <code>BaseModel</code>, so feel free to mix strings, numbers or more complex types:</p> <pre><code>from pydantic import BaseModel, Field\nfrom pfd_toolkit import load_reports, LLM, Extractor\n\n# Define feature model with pydantic\nclass MyFeatures(BaseModel):\n    age: int\n    cause_of_death: str\n</code></pre> <p>Next, load some report data and set up your LLM client. You then pass the feature model, the reports and the LLM client to an <code>Extractor</code> instance and call <code>.extract_features()</code>:</p> <pre><code>reports = load_reports(category=\"all\", start_date=\"2024-01-01\", end_date=\"2024-12-31\")\nllm_client = LLM(api_key=\"YOUR-API-KEY\")\n\nextractor = Extractor(\n    feature_model=MyFeatures,\n    reports=reports,\n    llm=llm_client\n)\n\nresult_df = extractor.extract_features()\n</code></pre> <p><code>result_df</code> now contains the new <code>age</code> and <code>cause_of_death</code> columns. You can repeat the call with a different feature model to extract further information \u2013 the cached results mean previously processed rows will not be re-sent to the LLM unless you clear the cache with <code>.reset()</code>.</p>"},{"location":"extractor/basics/#choosing-which-sections-the-llm-reads","title":"Choosing which sections the LLM reads","text":"<p><code>Extractor</code> lets you decide exactly which parts of the report are presented to the model. Each <code>include_*</code> flag mirrors one of the columns loaded by <code>load_reports</code>. Turning fields off reduces the amount of text sent to the LLM which often speeds up requests and lowers token usage.</p> <pre><code>extractor = Extractor(\n    llm=llm_client,\n    reports=reports,\n    include_investigation=True,\n    include_circumstances=True,\n    include_concerns=False  # Skip coroner's concerns if not relevant\n)\n</code></pre> <p>In this example only the investigation and circumstances sections are provided to the LLM. The coroner's concerns are omitted entirely. Limiting the excerpt like this often improves accuracy and drastically reduces token costs. However, be careful you're not turning 'off' a report section which is genuinely useful for your query.</p>"},{"location":"extractor/caching/","title":"Caching and exporting results","text":"<p><code>Extractor</code> caches every LLM response so repeated calls with the same prompt reuse previous results. Export the cache before you shut down and import it in a future session to avoid paying for the same completions twice.</p> <pre><code>extractor.export_cache(\"my_cache.pkl\")\n...\nextractor.import_cache(\"my_cache.pkl\")\n</code></pre> <p>If you want to start fresh, call <code>reset()</code> to clear cached feature values and token estimates. This is useful when you wish to re-run <code>extract_features</code> on the same DataFrame with a different feature model. <code>reset</code> returns the instance so you can immediately chain another call:</p> <pre><code>clean_df = extractor.reset().extract_features(feature_model=NewModel)\n</code></pre> <p>The returned DataFrame contains your newly extracted features and an empty cache ready for further runs.</p>"},{"location":"extractor/spans/","title":"Capturing text spans","text":"<p>Sometimes you want to know exactly which lines from the report led the model to a assign a particular value to a given report's field. </p> <p>For example, say we asked the model to identify whether the deceased is a child and the model outputs <code>True</code> for a particular report, we might want to know whether this was because age is explicitly recorded (e.g. \"The deceased was aged 16\") or implied based on context (e.g. \"The deceased was being seen by CAMHS prior to their death\").</p> <p><code>Extractor</code> can add these quotations (or 'spans') automatically. This is...</p> <ul> <li>Great for performance, because we're instructing the model to identify evidence for a feature value before it is assigned, reducing the risk of false positives.</li> <li>Great for human verification, because we can easily verify whether the model's evidence matches its assignment for each report.</li> </ul>"},{"location":"extractor/spans/#include-spans","title":"Include spans","text":"<p><code>.extract_features()</code> accepts a <code>produce_spans</code> flag. When enabled, a new column starting with <code>spans_</code> is created for every feature.</p> <p>For example, in our above example where we extract feature \"child\", a separate column called \"spans_child\" will be created. Each <code>spans_</code> column contains verbatim snippets from the report which justify the extracted value.</p> <pre><code>class ChildID(BaseModel):\n    child: bool = Field(..., description=\"Whether the deceased is a child (under 18)\")\n\nresult = extractor.extract_features(\n    feature_model=ChildID,\n    produce_spans=True,\n)\nresult\n</code></pre> <p>The quotes returned in the spans are kept as short as possible but should always match the original text verbatum. Multiple snippets are separated with semicolons.</p>"},{"location":"extractor/spans/#include-drop-spans","title":"Include &amp; drop spans","text":"<p>If you're not interested in verifying the output, you might want to remove the identified spans from the returned DataFrame after extraction. Set <code>drop_spans=True</code> to remove all <code>spans_</code> columns.</p> <p>As mentioned before, producing but later dropping spans is still likely to improve performance, because you're forcing the model to generate evidence as part of its internal workings out.</p> <pre><code>extractor.extract_features(\n    feature_model=DemoModel,\n    produce_spans=True,\n    drop_spans=True,\n)\n</code></pre>"},{"location":"extractor/summarising/","title":"Summaries &amp; token counts","text":"<p>Use <code>.summarise()</code> to condense each report into a short text snippet. The <code>trim_intensity</code> option controls how terse the summary should be. Calling <code>summarise</code> adds a <code>summary</code> column to your stored reports and keeps a copy on the instance under <code>extractor.summarised_reports</code> for later reuse.</p> <pre><code>summary_df = extractor.summarise(trim_intensity=\"medium\")\nsummary_df[[\"summary\"]].head()\n</code></pre> <p>The resulting DataFrame contains a new column (default name <code>summary</code>). You can specify a different column name via <code>result_col_name</code> if desired.</p>"},{"location":"extractor/summarising/#estimating-token-counts","title":"Estimating token counts","text":"<p>Token usage is important when working with paid APIs. The <code>estimate_tokens()</code> helper provides a quick approximation of how many tokens a text column will consume.</p> <pre><code>total = extractor.estimate_tokens()\nprint(f\"Total tokens in summaries: {total}\")\n</code></pre> <p><code>estimate_tokens</code> defaults to the summary column, but you can pass any text series via <code>col_name</code>. Set <code>return_series=True</code> to get a per-row estimate instead of the total.</p>"},{"location":"extractor/themes/","title":"Tagging reports with themes","text":"<p><code>Extractor</code> can be used to label reports with your own themes. Each field on the feature model represents a potential tag. In the model below the <code>falls_in_custody</code> field indicates whether a death occurred in police custody.</p> <p>Set <code>force_assign=True</code> so the LLM always returns either <code>True</code> or <code>False</code> for each field. <code>allow_multiple=True</code> lets a single report be marked with more than one theme if required.</p> <pre><code># For themes, we recommend always using the `bool` flag\nclass Themes(BaseModel):\n    falls_in_custody: bool = Field(description=\"Death occurred in police custody\")\n    medication_error: bool = Field(description=\"Issues with medication or dosing\")\n\nextractor = Extractor(\n    llm=llm_client,\n    feature_model=Themes,\n    reports=reports,\n    force_assign=True,\n    allow_multiple=True,\n)\n\nlabelled = extractor.extract_features()\n</code></pre> <p>The returned DataFrame includes a boolean column for each theme.</p>"},{"location":"extractor/themes/#discovering-themes-automatically","title":"Discovering themes automatically","text":"<p>Instead of having a prescribed list of themes ahead of time, you may wish to automatically discover themes contained within your selection of reports.</p> <p>Once summaries are available you can call <code>.discover_themes()</code> to let the LLM propose a list of recurring themes. <code>.discover_themes()</code> reads the <code>summary</code> column created by <code>.summarise()</code> (see Summaries &amp; token counts).</p> <p>The function returns a <code>pydantic</code> model describing the discovered themes. You can immediately feed that model back into <code>extract_features</code> to label each report.</p> <pre><code>IdentifiedThemes = extractor.discover_themes()\n\n# Optionally, inspect the newly identified themes:\n# print(IdentifiedThemes)\n\nassigned_reports = extractor.extract_features(\n                              feature_model=IdentifiedThemes,\n                              force_assign=True,\n                              allow_multiple=True)\n</code></pre> <p><code>discover_themes</code> accepts several parameters:</p> <ul> <li><code>warn_exceed</code> and <code>error_exceed</code> \u2013 soft and hard limits for the estimated token count of the combined summaries. Exceeding <code>error_exceed</code> raises an exception.</li> <li><code>max_themes</code> / <code>min_themes</code> \u2013 bound the number of themes the model should return.</li> <li><code>seed_topics</code> \u2013 either a string, list or <code>BaseModel</code> of starter topics. The LLM will incorporate these into the final list.</li> <li><code>extra_instructions</code> \u2013 free\u2011form text appended to the prompt, allowing you to steer the LLM towards particular areas of interest.</li> </ul>"},{"location":"loader/","title":"Load PFD reports","text":"<p>PFD Toolkit offers two ways to bring reports into a pandas DataFrame. Most users should call <code>load_reports</code> to download the weekly dataset that ships with the package.  Advanced users can take full control of the scraping pipeline using the <code>Scraper</code> class.</p> <p>The pages below explain each approach in detail:</p> <ul> <li>Loading report data \u2013 get a ready-made DataFrame with a single function call.</li> <li>Scraping module \u2013 build your own scraping workflow for maximum flexibility.</li> </ul>"},{"location":"loader/load_reports/","title":"Loading report data","text":"<p><code>load_reports()</code> is the quickest way to access PFD reports.  It loads a clean CSV that ships with the package and returns a pandas <code>DataFrame</code>. Each row represents a single report with columns mirroring the main sections.</p> <pre><code>from pfd_toolkit import load_reports\n\nreports = load_reports(\n    start_date=\"2024-01-01\",\n    end_date=\"2024-12-31\",\n    n_reports=None,\n)\n</code></pre> <p>Pass a <code>start_date</code> and <code>end_date</code> to restrict the date range, and optionally use <code>n_reports</code> to trim the DataFrame to the most recent n entries. Results are always sorted newest first.</p> <p>The dataset is refreshed weekly.  Simply run <code>pip install --upgrade pfd_toolkit</code> whenever a new snapshot is published.</p>"},{"location":"loader/load_reports/#caveats","title":"Caveats","text":"<p>To collect PFD reports, we run a scraping pipeline on the judiciary.uk website every week.  Our scraping methods assume that the host website will not change its basic layout. Should  the host change their website structure, our pipeline may fail to update its catelogue of  reports. The existing catelogue of reports will be unaffected.</p> <p>Should this happen, we will notify users at the top of the Home page and provide updates on when we can remedy the issue.</p>"},{"location":"loader/scraper/","title":"Scraping module","text":"<p><code>Scraper</code> lets you download PFD reports straight from the judiciary website and control each step of the extraction process. For most projects <code>load_reports()</code> is sufficient, but the scraping module gives you full transparency over how reports are gathered and how missing values are filled in. Use it when you need to customise request behaviour, adjust fallback logic or troubleshoot tricky reports.</p>"},{"location":"loader/scraper/#why-run-a-custom-scrape","title":"Why run a custom scrape?","text":"<p>The weekly datasets shipped with the package cover the majority of use cases. However there are two scenarios when direct scraping may be is preferable:</p> <ul> <li>Rapid updates \u2013 the official dataset lags up to a week behind new publications. Running your own scrape means you can see the newest reports immediately.</li> <li>Custom logic \u2013 while the dataset bundled with the package is a product of Vision-LLM scraping, you may also wish to enable HTML and .pdf scraping.</li> </ul>"},{"location":"loader/scraper/#creating-a-scraper","title":"Creating a scraper","text":"<pre><code>from pfd_toolkit import Scraper\n\nscraper = Scraper(\n    category=\"suicide\",           # judiciary.uk slug or \"all\"\n    start_date=\"2024-01-01\",\n    end_date=\"2024-12-31\",\n    scraping_strategy=[1, 2, 3],   # html \u2192 pdf \u2192 llm\n    max_workers=10,\n    delay_range=(1, 2),\n)\n</code></pre> <p>Pass in a category slug (or use <code>\"all\"</code>), a date range and any optional settings such as worker count, request delay or timeout. The <code>scraping_strategy</code> list defines which stages run and in what order. Each entry refers to the HTML, PDF and LLM steps respectively \u2013 set an index to <code>-1</code> to skip a step entirely.</p>"},{"location":"loader/scraper/#a-closer-look-at-the-pipeline","title":"A closer look at the pipeline","text":"<ol> <li>HTML scraping collects metadata directly from the web page. This is the fastest approach and usually recovers most fields.</li> <li>PDF fallback downloads the report PDF and extracts text with PyMuPDF. Missing fields from the HTML stage are filled in here if possible.</li> <li>LLM fallback hands off any unresolved blanks to an <code>LLM</code> client. This final pass is optional but can be invaluable for tricky reports where automated parsing fails.</li> </ol> <p>The stages cascade automatically\u2014if HTML scraping gathers everything you need, the PDF and LLM steps are skipped. You can reorder or disable steps entirely by tweaking <code>scraping_strategy</code>.</p>"},{"location":"loader/scraper/#running-a-scrape","title":"Running a scrape","text":"<p>After initialisation, call <code>scrape_reports()</code> to run the full scrape:</p> <pre><code>df = scraper.scrape_reports()\n</code></pre> <p>The results are cached on <code>scraper.reports</code> as a pandas DataFrame. This cache lets you rerun individual stages without hitting the network again. If more reports are published later you can update the existing DataFrame with <code>top_up()</code>:</p> <pre><code>updated = scraper.top_up(existing_df=df, end_date=\"2025-01-31\", clean=True)\n</code></pre> <p><code>top_up()</code> only fetches new pages, meaning you avoid repeating work and keep the original ordering intact. When <code>clean=True</code> the new and existing rows are passed through <code>Cleaner.clean_reports()</code> for optional LLM-powered tidying.</p>"},{"location":"loader/scraper/#applying-the-llm-fallback-separately","title":"Applying the LLM fallback separately","text":"<p>Sometimes you may want to review scraped results before running the LLM stage. <code>run_llm_fallback()</code> accepts a DataFrame (typically the output of <code>scrape_reports()</code> or <code>top_up()</code>) and attempts to fill any remaining blanks using your configured language model:</p> <pre><code>llm_df = scraper.run_llm_fallback(df)\n</code></pre>"},{"location":"loader/scraper/#threading-and-polite-scraping","title":"Threading and polite scraping","text":"<p><code>Scraper</code> uses a thread pool to speed up network requests. The <code>max_workers</code> and <code>delay_range</code> settings let you tune throughput and avoid overloading the server. The default one\u2013two second delay between requests mirrors human browsing behaviour and greatly reduces the risk of your IP address being flagged.</p>"},{"location":"loader/scraper/#inspecting-results","title":"Inspecting results","text":"<p>Every scrape writes a timestamp column when <code>include_time_stamp=True</code>. This can be useful for auditing or for merging multiple scrapes. All fields that could not be extracted are set to mising values, making gaps explicit in the final dataset. Use standard pandas operations to analyse or filter the DataFrame.</p>"},{"location":"loader/scraper/#caveats","title":"Caveats","text":"<p>Since scraping relies on the judiciary.uk website, any changes to layout could easily break parsers. The toolkit aims to handle common edge cases, but if you rely on scraping for production work you should keep an eye on logs and be ready to adapt your strategy. Also remember that running the LLM stage incurs API costs if you use a paid provider.</p> <p>See the API reference for a detailed breakdown of every argument and attribute.</p>"},{"location":"reference/cleaner/","title":"<code>Cleaner</code>","text":"<p>Batch-clean PFD report fields with an LLM.</p> <p>The cleaner loops over selected columns, builds field-specific prompts, calls attr:<code>llm.generate</code>, and writes the returned text back into a copy of the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>DataFrame</code> <p>Input DataFrame returned by :class:<code>~pfd_toolkit.scraper.PFDScraper</code> or similar.</p> required <code>llm</code> <code>LLM</code> <p>Instance of :class:<code>~pfd_toolkit.llm.LLM</code> used for prompting.</p> required <code>include_coroner</code> <code>bool</code> <code>True</code> <code>include_receiver</code> <code>bool</code> <code>True</code> <code>include_area</code> <code>bool</code> <code>True</code> <code>include_investigation</code> <code>bool</code> <p>Flags controlling which columns are processed.</p> <code>True</code> <code>include_circumstances</code> <code>bool</code> <p>Flags controlling which columns are processed.</p> <code>True</code> <code>include_concerns</code> <code>bool</code> <p>Flags controlling which columns are processed.</p> <code>True</code> <code>coroner_prompt</code> <code>str</code> <code>None</code> <code>area_prompt</code> <code>str</code> <code>None</code> <code>receiver_prompt</code> <code>str</code> <code>None</code> <code>investigation_prompt</code> <code>str</code> <code>None</code> <code>circumstances_prompt</code> <code>str or None</code> <p>Custom prompt templates.  When <code>None</code>, defaults based on :attr:<code>CLEANER_PROMPT_CONFIG</code>.</p> <code>None</code> <code>concerns_prompt</code> <code>str or None</code> <p>Custom prompt templates.  When <code>None</code>, defaults based on :attr:<code>CLEANER_PROMPT_CONFIG</code>.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Emit info-level logs for each batch when <code>True</code>.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>cleaned_reports</code> <code>DataFrame</code> <p>Result of the last call to meth:<code>clean_reports</code>.</p> <code>coroner_prompt_template, area_prompt_template, ...</code> <code>str</code> <p>Finalised prompt strings actually sent to the model.</p> <p>Examples:</p> <p>Basic usage::</p> <pre><code>cleaner = Cleaner(df, llm, include_coroner=False, verbose=True)\ncleaned_df = cleaner.clean_reports()\ncleaned_df.head()\n</code></pre>"},{"location":"reference/cleaner/#pfd_toolkit.Cleaner.clean_reports","title":"clean_reports","text":"<pre><code>clean_reports(anonymise=False)\n</code></pre> <p>Run LLM-based cleaning for the configured columns.</p> <p>The method operates in place on a copy of attr:<code>self.reports</code>, so the original DataFrame is never mutated.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A new DataFrame in which the selected columns have been replaced by the LLM output (or left unchanged when the model returns an error marker).</p> <p>Parameters:</p> Name Type Description Default <code>anonymise</code> <code>bool</code> <p>When <code>True</code> append an instruction to the prompts for the investigation, circumstances and concerns fields telling the language model to replace any personal names and pronouns with they/them/their.</p> <code>False</code> <p>Examples:</p> <p>Basic usage::</p> <pre><code>cleaned = cleaner.clean_reports()\ncleaned.equals(df)\n</code></pre>"},{"location":"reference/cleaner/#pfd_toolkit.Cleaner.generate_prompt_template","title":"generate_prompt_template","text":"<pre><code>generate_prompt_template()\n</code></pre> <p>Return the prompt templates used for each field.</p> <p>The returned dictionary maps DataFrame column names to the full prompt text with a <code>[TEXT]</code> placeholder appended to illustrate how the prompt will look during :meth:<code>clean_reports</code>.</p>"},{"location":"reference/extractor/","title":"<code>Extractor</code>","text":"<p>Extract custom features from Prevention of Future Death reports using an LLM.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>LLM</code> <p>Instance of :class:<code>~pfd_toolkit.llm.LLM</code> used for prompting.</p> required <code>reports</code> <code>DataFrame</code> <p>DataFrame of PFD reports. If provided, it will be copied and stored on the instance.</p> <code>None</code> <code>include_date</code> <code>bool</code> <code>False</code> <code>include_coroner</code> <code>bool</code> <code>False</code> <code>include_area</code> <code>bool</code> <code>False</code> <code>include_receiver</code> <code>bool</code> <code>False</code> <code>include_investigation</code> <code>(bool,)</code> <p>Flags controlling which existing report columns are included in the text sent to the LLM.</p> <code>True</code> <code>include_circumstances</code> <code>(bool,)</code> <p>Flags controlling which existing report columns are included in the text sent to the LLM.</p> <code>True</code> <code>include_concerns</code> <code>(bool,)</code> <p>Flags controlling which existing report columns are included in the text sent to the LLM.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Emit extra logging when <code>True</code>.</p> <code>False</code>"},{"location":"reference/extractor/#pfd_toolkit.Extractor.discover_themes","title":"discover_themes","text":"<pre><code>discover_themes(\n    *,\n    warn_exceed=100000,\n    error_exceed=500000,\n    max_themes=None,\n    min_themes=None,\n    extra_instructions=None,\n    seed_topics=None,\n)\n</code></pre> <p>Use an LLM to automatically discover report themes.</p> <p>The method expects :meth:<code>summarise</code> to have been run so that a summary column exists. All summaries are concatenated into one prompt sent to the LLM. The LLM should return a JSON object mapping theme names to descriptions. A new <code>pydantic</code> model is built from this mapping and stored as attr:<code>feature_model</code>.</p> <p>Parameters:</p> Name Type Description Default <code>warn_exceed</code> <code>int</code> <p>Emit a warning if the estimated token count exceeds this value. Defaults to <code>100000</code>.</p> <code>100000</code> <code>error_exceed</code> <code>int</code> <p>Raise a <code>ValueError</code> if the estimated token count exceeds this value. Defaults to <code>500000</code>.</p> <code>500000</code> <code>max_themes</code> <code>int or None</code> <p>Instruct the LLM to identify no more than this number of themes when provided.</p> <code>None</code> <code>min_themes</code> <code>int or None</code> <p>Instruct the LLM to identify at least this number of themes when provided.</p> <code>None</code> <code>extra_instructions</code> <code>str</code> <p>Additional instructions appended to the theme discovery prompt.</p> <code>None</code> <code>seed_topics</code> <code>str | list[str] | BaseModel</code> <p>Optional seed topics to include in the prompt. These are treated as starting suggestions and the model should incorporate them into a broader list of themes.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[BaseModel]</code> <p>The generated feature model containing discovered themes.</p>"},{"location":"reference/extractor/#pfd_toolkit.Extractor.estimate_tokens","title":"estimate_tokens","text":"<pre><code>estimate_tokens(col_name=None, return_series=False)\n</code></pre> <p>Estimate token counts for all rows of a given column using  :mod:<code>tiktoken</code>.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Name of the column containing report summaries. Defaults to :pyattr:<code>summary_col</code>, which is generated after running meth:<code>summarise</code>.</p> <code>None</code> <code>return_series</code> <code>bool</code> <p>Returns a pandas.Series of per-row token counts for that field if <code>True</code>, or an integer if <code>False</code>. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[int, Series]</code> <p>If <code>return_series</code> is <code>False</code>, returns an <code>int</code> representing the total sum of all token counts across all rows for the provided field. If <code>return_series</code> is <code>True</code>, returns a :class:<code>pandas.Series</code> of token counts aligned to attr:<code>self.reports</code> for the provided field.</p>"},{"location":"reference/extractor/#pfd_toolkit.Extractor.export_cache","title":"export_cache","text":"<pre><code>export_cache(path='extractor_cache.pkl')\n</code></pre> <p>Save the current cache to <code>path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Full path to the cache file including the filename. If <code>path</code> is a directory, <code>extractor_cache.pkl</code> will be created inside it.</p> <code>'extractor_cache.pkl'</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the written cache file.</p>"},{"location":"reference/extractor/#pfd_toolkit.Extractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(\n    reports=None,\n    *,\n    feature_model=None,\n    produce_spans=False,\n    drop_spans=False,\n    force_assign=False,\n    allow_multiple=False,\n    schema_detail=\"minimal\",\n    extra_instructions=None,\n    skip_if_present=True,\n)\n</code></pre> <p>Run feature extraction for the given reports.</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>DataFrame</code> <p>DataFrame of reports to process. Defaults to the instance's stored reports if omitted.</p> <code>None</code> <code>feature_model</code> <code>type[BaseModel]</code> <p>Pydantic model describing the features to extract. Must be provided on first call or after calling :meth:<code>discover_themes</code>.</p> <code>None</code> <code>produce_spans</code> <code>bool</code> <p>When <code>True</code>, create <code>spans_</code> versions of each feature to capture the supporting text snippets. Defaults to <code>False</code>.</p> <code>False</code> <code>drop_spans</code> <code>bool</code> <p>When <code>True</code> and <code>produce_spans</code> is also <code>True</code>, remove all <code>spans_</code> columns from the returned DataFrame after extraction. If <code>produce_spans</code> is <code>False</code> a warning is emitted and no columns are dropped. Defaults to <code>False</code>.</p> <code>False</code> <code>force_assign</code> <code>bool</code> <p>When <code>True</code>, the LLM is instructed to avoid returning :data:<code>GeneralConfig.NOT_FOUND_TEXT</code> for any feature.</p> <code>False</code> <code>allow_multiple</code> <code>bool</code> <p>Allow a report to be assigned to multiple categories when <code>True</code>.</p> <code>False</code> <code>schema_detail</code> <code>('full', 'minimal')</code> <p>Level of detail for the feature schema included in the prompt.</p> <code>\"full\"</code> <code>extra_instructions</code> <code>str</code> <p>Additional instructions injected into each prompt before the schema.</p> <code>None</code> <code>skip_if_present</code> <code>bool</code> <p>When <code>True</code> (default), skip rows when any feature column already holds a non-missing value that is not equal to :data:<code>GeneralConfig.NOT_FOUND_TEXT</code>. This assumes the row has been processed previously and is logged in an instance of <code>Extractor.cache</code></p> <code>True</code>"},{"location":"reference/extractor/#pfd_toolkit.Extractor.import_cache","title":"import_cache","text":"<pre><code>import_cache(path='extractor_cache.pkl')\n</code></pre> <p>Load cache from <code>path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Full path to the cache file including the filename. If <code>path</code> is a directory, <code>extractor_cache.pkl</code> will be loaded from inside it.</p> <code>'extractor_cache.pkl'</code>"},{"location":"reference/extractor/#pfd_toolkit.Extractor.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> <p>Reset internal caches and intermediate state.</p> <p>This clears any cached feature extraction results and token estimations so that :meth:<code>extract_features</code> can be run again on the same reports.  The instance itself is returned to allow method chaining, e.g. <code>extractor.reset().extract_features()</code>.</p>"},{"location":"reference/extractor/#pfd_toolkit.Extractor.summarise","title":"summarise","text":"<pre><code>summarise(\n    result_col_name=\"summary\",\n    trim_intensity=\"medium\",\n    extra_instructions=None,\n)\n</code></pre> <p>Summarise selected report fields into one column using the LLM.</p> <p>Parameters:</p> Name Type Description Default <code>result_col_name</code> <code>str</code> <p>Name of the summary column. Defaults to <code>\"summary\"</code>.</p> <code>'summary'</code> <code>trim_intensity</code> <code>('low', 'medium', 'high', 'very high')</code> <p>Controls how concise the summary should be. Defaults to <code>\"medium\"</code>.</p> <code>\"low\"</code> <code>extra_instructions</code> <code>str</code> <p>Additional instructions to append to the prompt before the report excerpt.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A new DataFrame identical to the one provided at initialisation with an extra summary column.</p>"},{"location":"reference/llm/","title":"<code>LLM</code>","text":"<p>Wrapper around the OpenAI Python SDK for batch prompting and PDF vision fallback.</p> <p>The helper provides:</p> <ul> <li>A generic meth:<code>self.generate()</code> that optionally supports vision   inputs and pydantic validation.</li> <li>A PDF-to-image utility used by   meth:<code>self._call_llm_fallback()</code> - the method the scraper invokes when   HTML and PDF heuristics fail.</li> <li>Built-in back-off and host-wide throttling via a semaphore.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>OpenAI (or proxy) API key.</p> <code>None</code> <code>model</code> <code>str</code> <p>Chat model name; defaults to <code>\"gpt-4.1-mini\"</code>.</p> <code>'gpt-4.1-mini'</code> <code>base_url</code> <code>str or None</code> <p>Override the OpenAI endpoint (for Azure/OpenRouter etc.).</p> <code>None</code> <code>max_workers</code> <code>int</code> <p>Maximum parallel workers for batch calls and for the global semaphore.</p> <code>8</code> <code>temperature</code> <code>float</code> <p>Sampling temperature used for all requests; defaults to <code>0.0</code>.</p> <code>0.0</code> <code>seed</code> <code>int or None</code> <p>Optional deterministic seed value passed to the OpenAI API. validation_attempts : int, optional Number of times to retry when parsing LLM output into a <code>pydantic</code> model fails. Defaults to <code>2</code>.</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None</code> <p>Override the HTTP timeout in seconds. If omitted, the OpenAI client default of 600\u202fseconds (10\u202fminutes) is used.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>_sem</code> <code>Semaphore</code> <p>Global semaphore that limits concurrent requests to max_workers.</p> <code>client</code> <code>Client</code> <p>Low-level SDK client configured with key and base URL.</p> <p>Examples:</p> <p>Basic usage::</p> <pre><code>llm = LLM(api_key=\"sk-...\", model=\"gpt-4o-mini\", temperature=0.2,\n          timeout=600)\nout = llm.generate([\"Hello world\"])\nout[0]\n</code></pre>"},{"location":"reference/llm/#pfd_toolkit.LLM.estimate_tokens","title":"estimate_tokens","text":"<pre><code>estimate_tokens(texts, model=None)\n</code></pre> <p>Return token counts for text using <code>tiktoken</code>.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>list[str] | str</code> <p>Input strings to tokenise.</p> required <code>model</code> <code>str</code> <p>Model name for selecting the encoding. Defaults to <code>self.model</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>Token counts in the same order as <code>texts</code>.</p>"},{"location":"reference/llm/#pfd_toolkit.LLM.generate","title":"generate","text":"<pre><code>generate(\n    prompts,\n    images_list=None,\n    response_format=None,\n    max_workers=None,\n    tqdm_extra_kwargs=None,\n)\n</code></pre> <p>Run many prompts either sequentially or in parallel.</p> <pre><code>    Parameters\n</code></pre> <pre><code>    prompts : list[str]\n        List of user prompts. One prompt per model call.\n\n    images_list : list[list[bytes]] or None, optional\n        For vision models: a parallel list where each inner list\n        holds **base64-encoded** JPEG pages for that prompt.  Use\n        *None* to send no images.\n\n    response_format : type[pydantic.BaseModel] or None, optional\n        If provided, each response is parsed into that model via the\n        *beta/parse* endpoint; otherwise a raw string is returned.\n\n    max_workers : int or None, optional\n        Thread count just for this batch.  When ``None``, fall back to\n        the instance-wide :py:attr:`max_workers`.\n</code></pre> <pre><code>    Returns\n</code></pre> <pre><code>    list[Union[pydantic.BaseModel, str]]\n        Results in the same order as `prompts`.\n</code></pre> <pre><code>    Raises\n</code></pre> <pre><code>    openai.RateLimitError\n        Raised only if the exponential back-off exhausts all retries.\n    openai.APIConnectionError\n        Raised if network issues persist beyond the retry window.\n    openai.APITimeoutError\n        Raised if the API repeatedly times out.\n</code></pre> <pre><code>    Examples\n</code></pre> <pre><code>    Generate multiple summaries::\n\n        msgs = [\"Summarise:\n</code></pre> <p>\" + txt for txt in docs]             summaries = llm.generate(msgs, max_workers=8)</p>"},{"location":"reference/loader/","title":"<code>load_reports</code>","text":"<p>Utility for loading the fully-cleaned Prevention of Future Death report dataset shipped with pfd_toolkit as a :class:<code>pandas.DataFrame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>start_date</code> <code>str</code> <p>Inclusive lower bound for the report date in the <code>YYYY-MM-DD</code> format.</p> <code>'2000-01-01'</code> <code>end_date</code> <code>str</code> <p>Inclusive upper bound for the report date in the <code>YYYY-MM-DD</code> format.</p> <code>'2050-01-01'</code> <code>n_reports</code> <code>int or None</code> <p>If given, keep only the most recent n_reports (based on the \u201cDate\u201d column) after filtering by date. If <code>None</code> (the default), return all reports in the specified date range.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Reports filtered by date, sorted newest-first, and (optionally) truncated to the first n_reports rows.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If start_date is after end_date.</p> <code>FileNotFoundError</code> <p>If the bundled CSV cannot be located (i.e. a package-level error).</p> <p>Examples:</p> <p>Load reports for a specific period::</p> <pre><code>from pfd_toolkit import load_reports\ndf = load_reports(start_date=\"2020-01-01\", end_date=\"2022-12-31\", n_reports=1000)\ndf.head()\n</code></pre>"},{"location":"reference/scraper/","title":"<code>Scraper</code>","text":"<p>Scrape UK \u201cPrevention of Future Death\u201d (PFD) reports into a :class:<code>pandas.DataFrame</code>.</p> <p>The extractor runs in three cascading layers (<code>html \u2192 pdf \u2192 llm</code>), each independently switchable.</p> <ol> <li>HTML scrape \u2013 parse metadata and rich sections directly from    the web page.</li> <li>PDF fallback \u2013 download the attached PDF and extract text with    PyMuPDF for any missing fields.</li> <li>LLM fallback \u2013 delegate unresolved gaps to a Large Language    Model supplied via llm.</li> </ol> <p>Each layer can be enabled or disabled via <code>scraping_strategy</code>.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>LLM | None</code> <p>Client implementing <code>_call_llm_fallback()</code>; required only when the LLM stage is enabled.</p> <code>None</code> <code>category</code> <code>str</code> <p>Judiciary category slug (e.g. <code>\"suicide\"</code>, <code>\"hospital_deaths\"</code>) or <code>\"all\"</code>.</p> <code>'all'</code> <code>start_date</code> <code>str</code> <p>Inclusive lower bound for the report date in the <code>YYYY-MM-DD</code> format.</p> <code>'2000-01-01'</code> <code>end_date</code> <code>str</code> <p>Inclusive upper bound for the report date in the <code>YYYY-MM-DD</code> format.</p> <code>'2050-01-01'</code> <code>max_workers</code> <code>int</code> <p>Thread-pool size for concurrent scraping.</p> <code>10</code> <code>max_requests</code> <code>int</code> <p>Maximum simultaneous requests per host (enforced with a semaphore).</p> <code>5</code> <code>delay_range</code> <code>tuple[float, float] | None</code> <p>Random delay (seconds) before every request. Use <code>None</code> to disable (not recommended).</p> <code>(1, 2)</code> <code>timeout</code> <code>int</code> <p>Per-request timeout in seconds.</p> <code>60</code> <code>scraping_strategy</code> <code>list[int] | tuple[int, int, int]</code> <p>Defines the order in which HTML, PDF and LLM scraping are attempted. The sequence indexes correspond to <code>(HTML, PDF, LLM)</code>. Provide <code>-1</code> to disable a stage.  For example <code>[1, 2, -1]</code> runs HTML first, then PDF, and disables LLM scraping.</p> <code>[1, 2, 3]</code> <code>include_url</code> <code>bool</code> <code>True</code> <code>include_id</code> <code>bool</code> <code>True</code> <code>include_date</code> <code>bool</code> <code>True</code> <code>include_coroner</code> <code>bool</code> <code>True</code> <code>include_area</code> <code>bool</code> <code>True</code> <code>include_receiver</code> <code>bool</code> <code>True</code> <code>include_investigation</code> <code>bool</code> <code>True</code> <code>include_circumstances</code> <code>bool</code> <code>True</code> <code>include_concerns</code> <code>bool</code> <p>Flags controlling which columns appear in the output DataFrame.</p> <code>True</code> <code>include_time_stamp</code> <code>bool</code> <p>Flags controlling which columns appear in the output DataFrame.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Emit debug-level logs when True.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>reports</code> <code>DataFrame | None</code> <p>Cached result of the last call to meth:<code>scrape_reports</code> or meth:<code>top_up</code>.</p> <code>report_links</code> <code>list[str]</code> <p>URLs discovered by meth:<code>get_report_links</code>.</p> <code>NOT_FOUND_TEXT</code> <code>str</code> <p>Placeholder value set when a field cannot be extracted.</p> <p>Examples:</p> <p>Basic usage::</p> <pre><code>from pfd_toolkit import Scraper\nscraper = Scraper(\n    category=\"suicide\",\n    start_date=\"2020-01-01\",\n    end_date=\"2022-12-31\",\n    scraping_strategy=[1, 2, 3],\n    llm=my_llm_client,\n)\ndf = scraper.scrape_reports()          # full scrape\nnewer_df = scraper.top_up(df)          # later \"top-up\"\nadded_llm_df = scraper.run_llm_fallback(df)  # apply LLM retro-actively\n</code></pre>"},{"location":"reference/scraper/#pfd_toolkit.Scraper.get_report_links","title":"get_report_links","text":"<pre><code>get_report_links()\n</code></pre> <p>Discover individual report URLs for the current query, across all pages.</p> <p>Iterates through _get_report_href_values (which collects URLs for a single page).</p> <p>Pagination continues until a page yields zero new links.</p> <p>Returns:</p> Type Description <code>list[str] | None</code> <p>All discovered URLs, or None if no links were found for the given category/date window.</p>"},{"location":"reference/scraper/#pfd_toolkit.Scraper.run_llm_fallback","title":"run_llm_fallback","text":"<pre><code>run_llm_fallback(reports_df=None)\n</code></pre> <p>Ask the LLM to fill cells still set to attr:<code>self.NOT_FOUND_TEXT</code>.</p> <p>Only the missing fields requested via <code>include_*</code> flags are sent to the model, along with the report\u2019s PDF bytes (when available).</p> <p>Parameters:</p> Name Type Description Default <code>reports_df</code> <code>DataFrame | None</code> <p>DataFrame to process.  Defaults to attr:<code>self.reports</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Same shape as <code>reports_df</code>, updated in place and re-cached to attr:<code>self.reports</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no LLM client was supplied at construction time.</p> <p>Examples:</p> <p>Run the fallback step after scraping::</p> <pre><code>updated_df = scraper.run_llm_fallback()\n</code></pre>"},{"location":"reference/scraper/#pfd_toolkit.Scraper.scrape_reports","title":"scrape_reports","text":"<pre><code>scrape_reports()\n</code></pre> <p>Execute a full scrape with the Class configuration.</p> Workflow <ol> <li>Call meth:<code>get_report_links</code>.</li> <li>Extract each report according to <code>scraping_strategy</code>.</li> <li>Cache the final DataFrame to attr:<code>self.reports</code>.</li> </ol> <p>Returns:</p> Type Description <code>DataFrame</code> <p>One row per report.  Column presence matches the <code>include_*</code> flags. The DataFrame is empty if nothing was scraped.</p> <p>Examples:</p> <p>Scrape reports and inspect columns::</p> <pre><code>df = scraper.scrape_reports()\ndf.columns\n</code></pre>"},{"location":"reference/scraper/#pfd_toolkit.Scraper.top_up","title":"top_up","text":"<pre><code>top_up(\n    old_reports=None,\n    start_date=None,\n    end_date=None,\n    clean=False,\n)\n</code></pre> <p>Check for and append new PFD reports within the current parameters.</p> <p>If new links are found they are scraped and appended to attr:<code>self.reports</code>.  Any URL (or ID) already present in old_reports is skipped.</p> <p>Optionally, you can override the start_date and end_date parameters from <code>self</code> for this call only.</p> <p>Parameters:</p> Name Type Description Default <code>old_reports</code> <code>DataFrame | None</code> <p>Existing DataFrame.  Defaults to attr:<code>self.reports</code>.</p> <code>None</code> <code>start_date</code> <code>str | None</code> <p>Optionally override the scraper\u2019s date window for this call only.</p> <code>None</code> <code>end_date</code> <code>str | None</code> <p>Optionally override the scraper\u2019s date window for this call only.</p> <code>None</code> <code>clean</code> <code>bool</code> <p>When <code>True</code>, run :class:<code>~pfd_toolkit.Cleaner</code> on the newly scraped rows before merging them with existing reports.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>Updated DataFrame if new reports were added; None if no new records were found and old_reports was None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If old_reports lacks columns required for duplicate checks.</p> <p>Examples:</p> <p>Add new reports to an existing DataFrame::</p> <pre><code>updated = scraper.top_up(df, end_date=\"2023-01-01\")\nlen(updated) - len(df)  # number of new reports\n</code></pre>"},{"location":"reference/screener/","title":"<code>Screener</code>","text":"<p>Classifies a list of report texts against a user-defined topic using an LLM.</p> <p>This class takes a DataFrame of reports, a user query, and various configuration options to classify whether each report matches the query. It can either filter the DataFrame to return only matching reports or add a classification column to the original DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>LLM</code> <p>An instance of the LLM class from <code>pfd_toolkit</code>.</p> <code>None</code> <code>reports</code> <code>DataFrame</code> <p>A DataFrame containing Prevention of Future Death reports.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print more detailed logs. Defaults to False.</p> <code>False</code> <code>include_date</code> <code>bool</code> <p>Flag to determine if the 'Date' column is included. Defaults to False.</p> <code>False</code> <code>include_coroner</code> <code>bool</code> <p>Flag to determine if the 'CoronerName' column is included. Defaults to False.</p> <code>False</code> <code>include_area</code> <code>bool</code> <p>Flag to determine if the 'Area' column is included. Defaults to False.</p> <code>False</code> <code>include_receiver</code> <code>bool</code> <p>Flag to determine if the 'Receiver' column is included. Defaults to False.</p> <code>False</code> <code>include_investigation</code> <code>bool</code> <p>Flag to determine if the 'InvestigationAndInquest' column is included. Defaults to True.</p> <code>True</code> <code>include_circumstances</code> <code>bool</code> <p>Flag to determine if the 'CircumstancesOfDeath' column is included. Defaults to True.</p> <code>True</code> <code>include_concerns</code> <code>bool</code> <p>Flag to determine if the 'MattersOfConcern' column is included. Defaults to True.</p> <code>True</code> <p>Examples:</p> <p>Basic usage::</p> <pre><code>user_topic = \"medication errors\"\nllm_client = LLM()\nscreener = Screener(llm=llm_client, reports=reports_df)\nscreened_reports = screener.screen_reports(user_query=user_topic)\nprint(f\"Found {len(screened_reports)} report(s) on '{user_topic}'.\")\n</code></pre>"},{"location":"reference/screener/#pfd_toolkit.Screener.screen_reports","title":"screen_reports","text":"<pre><code>screen_reports(\n    reports=None,\n    user_query=None,\n    filter_df=True,\n    result_col_name=\"matches_query\",\n    produce_spans=False,\n    drop_spans=False,\n)\n</code></pre> <p>Classifies reports in the DataFrame against the user-defined topic using the LLM.</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>DataFrame</code> <p>If provided, this DataFrame will be used for screening, replacing any DataFrame stored in the instance for this call.</p> <code>None</code> <code>user_query</code> <code>str</code> <p>If provided, this query will be used, overriding any query stored in the instance for this call. The prompt template will be rebuilt.</p> <code>None</code> <code>filter_df</code> <code>bool</code> <p>If <code>True</code> the returned DataFrame is filtered to only matching reports. Defaults to <code>True</code>.</p> <code>True</code> <code>result_col_name</code> <code>str</code> <p>Name of the boolean column added when <code>filter_df</code> is <code>False</code>. Defaults to <code>\"matches_query\"</code>.</p> <code>'matches_query'</code> <code>produce_spans</code> <code>bool</code> <p>When <code>True</code> a <code>spans_matches_topic</code> column is created containing the text snippet that justified the classification. Defaults to <code>False</code>.</p> <code>False</code> <code>drop_spans</code> <code>bool</code> <p>When <code>True</code> and <code>produce_spans</code> is also <code>True</code>, the <code>spans_matches_topic</code> column is removed from the returned DataFrame. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Either a filtered DataFrame (if <code>filter_df</code> is <code>True</code>), or the original DataFrame with an added classification column.</p> <p>Examples:</p> <p>Example session::</p> <pre><code>reports_df = pd.DataFrame(data)\nscreener = Screener(LLM(), reports=reports_df)\n\n# Screen reports with the initial query\nfiltered_df = screener.screen_reports(user_query=\"medication safety\")\n\n# Screen the same reports with a new query and add a classification column\nclassified_df = screener.screen_reports(user_query=\"tree safety\", filter_df=False)\n</code></pre>"},{"location":"screener/","title":"Screen reports for relevancy","text":"<p>The <code>Screener</code> class filters PFD reports according to a plain\u2011English query. The following pages cover how to use it:</p> <ul> <li>Getting started \u2013 run your first screen and understand why an LLM beats simple keyword search.</li> <li>Additional options \u2013 annotate instead of filtering and control which columns are read.</li> <li>Tips for writing a good user query \u2013 craft prompts that get accurate results.</li> </ul>"},{"location":"screener/basics/","title":"Getting started","text":"<p>Natural-language filtering is one of the headline features of PFD Toolkit. The <code>Screener</code> class lets you describe a topic in plain English \u2013 e.g. \"deaths in police custody\" \u2013 and have an LLM screen reports, delivering you a curated dataset.</p> <p>You do not have to use <code>Screener</code> to benefit from the toolkit. If the built-in category tags are good enough, the <code>load_reports()</code> helper will give you a ready-made dataset without any LLM calls. <code>Screener</code> is offered for those projects that need something more nuanced than the provided broad category tags.</p> <p>To use the <code>Screener</code> you'll need to set up an LLM client.</p>"},{"location":"screener/basics/#a-minimal-example","title":"A minimal example","text":"<p>First, import the necessary modules, load reports and set up an <code>LLM</code> client:</p> <pre><code>from pfd_toolkit import load_reports, LLM, Screener\n\n# Grab the pre-processed April 2025 dataset\nreports = load_reports(category=\"all\",\n                       start_date=\"2025-04-01\",\n                       end_date=\"2025-04-30\")\n\n# Set up your LLM client (see \u201cCreating an LLM client\u201d for details)\nllm_client = LLM(api_key=\"YOUR-API-KEY\")\n</code></pre> <p>Then describe the reports you're interested in, pass the query to <code>Screener</code> and you'll be given a filtered dataset containing matching reports.</p> <pre><code>user_query = \"deaths in police custody\"\n\nscreener = Screener(\n    llm=llm_client,\n    reports=reports\n)\n\npolice_df = screener.screen_reports(user_query=user_query, filter_df=True)\n\nprint(f\"{len(police_df)} reports matched.\")\n&gt;&gt; \"13 reports matched.\"\n</code></pre>"},{"location":"screener/basics/#why-not-just-have-a-normal-search-function","title":"Why not just have a normal \"search\" function?","text":"<p>A keyword search is only as good as the exact words you type. Coroners, however, don't always follow a shared vocabulary. The same idea can surface in wildly different forms:</p> <ul> <li>Under-staffing might be written as \"staff shortages,\" \"inadequate nurse cover,\" or even \"resource constraints.\"</li> <li>Suicide in prisons may masquerade as \"self-inflicted injury while remanded,\" \"ligature event in cell,\" or appear across separate sentences.</li> </ul> <p>A keyword filter misses these variants unless you guess every synonym in advance. By contrast, an <code>LLM</code> understands the context behind your query and links the phrasing for you, which is exactly what <code>Screener</code> taps into.</p>"},{"location":"screener/options/","title":"Additional options","text":""},{"location":"screener/options/#annotation-vs-filtering","title":"Annotation vs. filtering","text":"<p>If <code>filter_df</code> is True (the default) <code>Screener</code> returns a trimmed DataFrame that contains only the reports the LLM marked as relevant to your query.</p> <p>Setting it to False activates annotate mode: every report/row from your original DataFrame is kept, and a boolean column is added denoting whether the report met your query or not. You can also rename this column with <code>result_col_name</code>.</p> <p>A common workflow is to screen once with <code>filter_df=False</code>, inspect a few borderline cases, then rerun with <code>filter_df=True</code> once you trust the settings.</p> <pre><code>screener = Screener(\n    llm=llm_client,\n    reports=reports,\n)\n\nannotated = screener.screen_reports(\n    user_query=user_query,\n    filter_df=False,    # &lt;--- create annotation column; don't filter out\n    result_col_name='custody_match'     # &lt;--- name of annotation column\n)\n</code></pre>"},{"location":"screener/options/#choosing-which-columns-the-llm-sees","title":"Choosing which columns the LLM 'sees'","text":"<p>By default the LLM model reads the narrative heavyweight sections of each report: investigation, circumstances and concerns. You can expose or hide any field with <code>include_*</code> flags.</p> <p>For example, if you are screening based on a specific cause of death, then you should consider setting <code>include_concerns</code> to False, as including this won't benefit your search.</p> <p>By contrast, if you are searching for a specific concern, then setting <code>include_investigation</code> and <code>include_circumstances</code> to False may improve accuracy, speed up your code, and lead to cheaper LLM calls.</p> <pre><code>user_query = \"Death from insulin overdose due to misprogrammed insulin pumps.\"\n\nscreener = Screener(\n    llm=llm_client,\n    reports=reports,\n    include_concerns=False    # &lt;--- Our query doesn't need this section\n)\n\nresult = screener.screen_reports(user_query=user_query)\n</code></pre> <p>In another example, let's say we are only interested in reports sent to a Member of Parliament. We'll want to turn off all default sections and only read from the receiver column.</p> <pre><code>user_query = \"Whether the report was sent to a Member of Parliament (MP)\"\n\nscreener = Screener(\n    llm=llm_client,\n    reports=reports,\n\n    # Turn off the defaults...\n    include_investigation=False,\n    include_circumstances=False,\n    include_concerns=False,\n\n    include_receiver=True       # &lt;--- Read from receiver section\n)\n\nresult = screener.screen_reports(user_query=user_query)\n</code></pre>"},{"location":"screener/options/#all-options-and-defaults","title":"All options and defaults","text":"Flag Report section What it's useful for Default <code>include_coroner</code> Coroner\u2019s name Simply the name of the coroner. Rarely needed for screening. <code>False</code> <code>include_area</code> Coroner\u2019s area Useful for geographic questions, e.g.\u00a0deaths in South-East England. <code>False</code> <code>include_receiver</code> Receiver(s) of the report Great for accountability queries, e.g. reports sent to NHS Wales. <code>False</code> <code>include_investigation</code> \u201cInvestigation &amp; Inquest\u201d section Contains procedural detail about the inquest. <code>True</code> <code>include_circumstances</code> \u201cCircumstances of Death\u201d section Describes what actually happened; holds key facts about the death. <code>True</code> <code>include_concerns</code> \u201cCoroner\u2019s Concerns\u201d section Lists the issues the coroner wants addressed \u2014 ideal for risk screening. <code>True</code>"},{"location":"screener/options/#returning-text-spans","title":"Returning text spans","text":"<p>Set <code>produce_spans=True</code> when calling <code>.screen_reports()</code> to capture the exact lines from the report that justified each classification. A new column called <code>spans_matches_topic</code> will be created containing these verbatim snippets. If you only want to use the spans internally, pass <code>drop_spans=True</code> to remove the column from the returned DataFrame after screening.</p> <pre><code>screener = Screener(llm=llm_client,\n                    reports=reports)\nannotated = screener.screen_reports(user_query=\"needle\", produce_spans=True, drop_spans=False)\n</code></pre>"},{"location":"screener/tips/","title":"Tips for writing a good user query","text":"<ol> <li>Stick to one core idea. Give the LLM a single, clear subject: \u201cfalls from hospital beds,\u201d \u201ccarbon-monoxide poisoning at home.\u201d In general, the shorter the prompt, the less room for misinterpretation.</li> <li>Avoid nested logic. Complex clauses like \u201csuicide and medication error but not in custody\u201d dilute the signal. Consider running separate screens (suicide; medication error; in custody) and combine or subtract results later with pandas.</li> <li>Let the model handle synonyms. You don\u2019t need \u201cdefective, faulty, malfunctioning\u201d all in the same query; \u201cmalfunctioning defibrillators\u201d is enough.</li> <li>Use positive phrasing. Negations (e.g. \u201cnot related to COVID-19\u201d) can flip the model\u2019s reasoning. Screen positively, set <code>filter_df</code> to False, then drop rows in pandas.</li> <li>Keep it readable. If your query needs multiple commas or parentheses, break it up. A one-line statement without side notes usually performs best.</li> </ol> <p>Examples:</p>  Less-effective query Why it struggles  Better query \u201cDeaths where someone slipped or fell in hospital corridors or patient rooms and maybe had fractures but not clinics\u201d Too long, multiple settings, negative clause \u201cFalls on inpatient wards\u201d \u201cFires or explosions causing death at home including gas leaks but not industrial accidents\u201d Mixes two ideas (home vs. industrial) plus a negation \u201cDomestic gas explosions\u201d \u201cCases involving children and allergic reactions to nuts during school outings\u201d Several concepts (age, allergen, setting) \u201cFatal nut allergy on school trip\u201d \u201cRailway incidents that resulted in death due to being hit by train while trespassing or at crossings\u201d Two scenarios joined by \u201cor\u201d; verbose \u201cTrespasser struck by train\u201d \u201cPatients dying because an ambulance was late or there was delay in emergency services arrival or they couldn't get one\u201d Chain of synonyms and clauses \u201cDeath from delayed ambulance\u201d \u201cErrors in giving anaesthesia, like too much anaesthetic, wrong drug, problems with intubation, etc.\u201d Long list invites confusion; \u201cetc.\u201d is vague \u201cAnaesthesia error\u201d"}]}