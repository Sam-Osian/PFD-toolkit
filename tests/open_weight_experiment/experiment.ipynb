{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8784f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pfd_toolkit\n",
      "  Downloading pfd_toolkit-0.4.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting adjusttext>=1.3.0 (from pfd_toolkit)\n",
      "  Downloading adjustText-1.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting backoff>=2.2.1 (from pfd_toolkit)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.13.4 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (4.13.5)\n",
      "Collecting dotenv>=0.9.9 (from pfd_toolkit)\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (0.28.1)\n",
      "Requirement already satisfied: openai>=1.88.0 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (2.8.1)\n",
      "Requirement already satisfied: pandas<2.2.3,>=2.2.2 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (2.2.2)\n",
      "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (2.11.10)\n",
      "Collecting pymupdf>=1.26.1 (from pfd_toolkit)\n",
      "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (2.32.4)\n",
      "Requirement already satisfied: tiktoken>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (0.12.0)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pfd_toolkit) (4.67.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from adjusttext>=1.3.0->pfd_toolkit) (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from adjusttext>=1.3.0->pfd_toolkit) (3.10.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from adjusttext>=1.3.0->pfd_toolkit) (1.16.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.13.4->pfd_toolkit) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.13.4->pfd_toolkit) (4.15.0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from dotenv>=0.9.9->pfd_toolkit) (1.2.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->pfd_toolkit) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->pfd_toolkit) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->pfd_toolkit) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->pfd_toolkit) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->pfd_toolkit) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.88.0->pfd_toolkit) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.88.0->pfd_toolkit) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.88.0->pfd_toolkit) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.3,>=2.2.2->pfd_toolkit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.3,>=2.2.2->pfd_toolkit) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->pfd_toolkit) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->pfd_toolkit) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->pfd_toolkit) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.9.0.post0->pfd_toolkit) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->pfd_toolkit) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->pfd_toolkit) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.9.0->pfd_toolkit) (2025.11.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjusttext>=1.3.0->pfd_toolkit) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjusttext>=1.3.0->pfd_toolkit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjusttext>=1.3.0->pfd_toolkit) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjusttext>=1.3.0->pfd_toolkit) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjusttext>=1.3.0->pfd_toolkit) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjusttext>=1.3.0->pfd_toolkit) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjusttext>=1.3.0->pfd_toolkit) (3.2.5)\n",
      "Downloading pfd_toolkit-0.4.0-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading adjustText-1.3.0-py3-none-any.whl (13 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf, dotenv, backoff, adjusttext, pfd_toolkit\n",
      "Successfully installed adjusttext-1.3.0 backoff-2.2.1 dotenv-0.9.9 pfd_toolkit-0.4.0 pymupdf-1.26.6\n"
     ]
    }
   ],
   "source": [
    "! pip install pfd_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf4bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pfd_toolkit import LLM, Screener\n",
    "from pfd_toolkit.config import GeneralConfig\n",
    "\n",
    "DATA_PATH = Path(\"../../ons_replication/PFD Toolkit--Consensus Comparison.xlsx\")\n",
    "RESULTS_PATH = Path(\"model_comparison.csv\")\n",
    "SHEET_NAME = \"Consensus annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37ee145",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SPECS = [\n",
    "    # OpenAI API models\n",
    "    {\"name\": \"gpt-4.1\", \"temperature\": 0},\n",
    "    {\"name\": \"gpt-4.1-mini\", \"temperature\": 0},\n",
    "    {\"name\": \"gpt-4.1-nano\", \"temperature\": 0},\n",
    "\n",
    "\n",
    "    # Ollama-hosted models\n",
    "    {\n",
    "        \"name\": \"mistral-nemo:12b\",\n",
    "        \"temperature\": 0,\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "        \"timeout\": 10**9,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mistral-small:22b\",\n",
    "        \"temperature\": 0,\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "        \"timeout\": 10**9,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mistral-small:24b\",\n",
    "        \"temperature\": 0,\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "        \"timeout\": 10**9,\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "user_query = \"\"\"\n",
    "Identify cases where the deceased was aged 18 or younger *clearly at the time of death* **and** \n",
    "the death was due to suicide. If suicide is not explicitly stated, you can use a strict balance of \n",
    "probabilities threshold to determine it as such. \n",
    "\n",
    "Age may not be explicitly stated, but could be implied through references such as \n",
    "**recent** use of child or adolescent services (e.g. CAMHS), attending school years \n",
    "(e.g. “Year 10”), or similar contextual indicators of being under 18 (again, under a \n",
    "strict balance of probabilities threshold).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b51e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reports() -> pd.DataFrame:\n",
    "    df = pd.read_excel(DATA_PATH, sheet_name=SHEET_NAME)\n",
    "    renamed = df.rename(\n",
    "        columns={\n",
    "            \"Ref\": GeneralConfig.COL_ID,\n",
    "            \"Investigation section\": GeneralConfig.COL_INVESTIGATION,\n",
    "            \"Circumstances of death section\": GeneralConfig.COL_CIRCUMSTANCES,\n",
    "            \"Matters of concern section\": GeneralConfig.COL_CONCERNS,\n",
    "            \"Post-consensus verdict: Is this a child suicide case? (Yes or No)\": \"consensus\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    reports = renamed[\n",
    "        [\n",
    "            GeneralConfig.COL_ID,\n",
    "            GeneralConfig.COL_INVESTIGATION,\n",
    "            GeneralConfig.COL_CIRCUMSTANCES,\n",
    "            GeneralConfig.COL_CONCERNS,\n",
    "            \"consensus\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    reports[\"consensus\"] = (\n",
    "        reports[\"consensus\"].astype(str).str.strip().str.lower() == \"yes\"\n",
    "    )\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f41cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(spec: dict[str, object], reports: pd.DataFrame) -> dict[str, float]:\n",
    "    model_name = spec[\"name\"]\n",
    "    llm_kwargs = {\n",
    "        \"api_key\": spec.get(\"api_key\", os.getenv(\"OPENAI_API_KEY\")),\n",
    "        \"max_workers\": 8,\n",
    "        \"model\": model_name,\n",
    "        \"seed\": 12345,\n",
    "        \"timeout\": spec.get(\"timeout\", 20),\n",
    "        \"temperature\": 1 if model_name.startswith(\"gpt-5\") else spec[\"temperature\"],\n",
    "    }\n",
    "\n",
    "    if \"base_url\" in spec:\n",
    "        llm_kwargs[\"base_url\"] = spec[\"base_url\"]\n",
    "\n",
    "    llm_client = LLM(**llm_kwargs)\n",
    "    screener = Screener(\n",
    "        llm=llm_client,\n",
    "        reports=reports,\n",
    "        include_investigation=True,\n",
    "        include_circumstances=True,\n",
    "        include_concerns=True,\n",
    "    )\n",
    "\n",
    "    classified = screener.screen_reports(\n",
    "        search_query=user_query,\n",
    "        filter_df=False,\n",
    "        result_col_name=\"model_pred\",\n",
    "    )\n",
    "\n",
    "    pred = classified[\"model_pred\"].astype(bool)\n",
    "    truth = classified[\"consensus\"].astype(bool)\n",
    "\n",
    "    tp = (pred & truth).sum()\n",
    "    tn = ((~pred) & (~truth)).sum()\n",
    "    fp = (pred & ~truth).sum()\n",
    "    fn = ((~pred) & truth).sum()\n",
    "\n",
    "    total = tp + tn + fp + fn\n",
    "    accuracy = (tp + tn) / total if total else float(\"nan\")\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) else float(\"nan\")\n",
    "    specificity = tn / (tn + fp) if (tn + fp) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee924547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparisons():\n",
    "    load_dotenv(\"../../api.env\")\n",
    "    reports = load_reports()\n",
    "\n",
    "    if RESULTS_PATH.exists():\n",
    "        results_df = pd.read_csv(RESULTS_PATH)\n",
    "    else:\n",
    "        results_df = pd.DataFrame(\n",
    "            columns=[\"model\", \"accuracy\", \"sensitivity\", \"specificity\"]\n",
    "        )\n",
    "\n",
    "    completed_models = set(results_df[\"model\"].astype(str))\n",
    "    models_to_run = [spec for spec in MODEL_SPECS if spec[\"name\"] not in completed_models]\n",
    "\n",
    "    if not models_to_run:\n",
    "        print(\"All models already tested.\")\n",
    "        return results_df\n",
    "\n",
    "    for spec in models_to_run:\n",
    "        print(f\"Testing model: {spec['name']}\")\n",
    "        results = evaluate_model(spec, reports)\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([results])], ignore_index=True)\n",
    "        results_df.to_csv(RESULTS_PATH, index=False)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4e7a44",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../ons_replication/PFD Toolkit--Consensus Comparison.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3013445857.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../api.env\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_reports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mRESULTS_PATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-3764537667.py\u001b[0m in \u001b[0;36mload_reports\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_reports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSHEET_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     renamed = df.rename(\n\u001b[1;32m      4\u001b[0m         columns={\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m\"Ref\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGeneralConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOL_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../ons_replication/PFD Toolkit--Consensus Comparison.xlsx'"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"../../api.env\")\n",
    "reports = load_reports()\n",
    "\n",
    "if RESULTS_PATH.exists():\n",
    "    results_df = pd.read_csv(RESULTS_PATH)\n",
    "else:\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"model\", \"accuracy\", \"sensitivity\", \"specificity\"]\n",
    "    )\n",
    "\n",
    "completed_models = set(results_df[\"model\"].astype(str))\n",
    "models_to_run = [spec for spec in MODEL_SPECS if spec[\"name\"] not in completed_models]\n",
    "\n",
    "if not models_to_run:\n",
    "    print(\"All models already tested.\")\n",
    "    return\n",
    "\n",
    "for spec in models_to_run:\n",
    "    print(f\"Testing model: {spec['name']}\")\n",
    "    results = evaluate_model(spec, reports)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([results])], ignore_index=True)\n",
    "    results_df.to_csv(RESULTS_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
