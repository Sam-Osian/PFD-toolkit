{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc171e8",
   "metadata": {},
   "source": [
    "# Open-weight model experiment\n",
    "\n",
    "Run the open-weight model comparison on the consensus dataset without relying on local data files. The notebook pulls the data directly from GitHub, loads any available API keys from env files next to the notebook, and saves results locally to a CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5123e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "! pip install -q pfd_toolkit ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60204560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7511f3824e54eac9baf49c2b578c77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Password(description='API key:', placeholder='Paste your key here'), Button(description='Set ke…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get API key\n",
    "\n",
    "import os\n",
    "from ipywidgets import Password, Button, VBox, HTML\n",
    "\n",
    "api_key_input = Password(\n",
    "    description=\"API key:\",\n",
    "    placeholder=\"Paste your key here\"\n",
    ")\n",
    "status = HTML(\"\")\n",
    "button = Button(description=\"Set key\")\n",
    "\n",
    "def set_api_key(_):\n",
    "    if api_key_input.value:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key_input.value\n",
    "        # clear the visible value\n",
    "        api_key_input.value = \"\"\n",
    "        status.value = \"<b>API key stored in this session.</b>\"\n",
    "    else:\n",
    "        status.value = \"<b>No key entered.</b>\"\n",
    "\n",
    "button.on_click(set_api_key)\n",
    "\n",
    "ui = VBox([api_key_input, button, status])\n",
    "ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b5a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b096b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import tempfile\n",
    "from urllib.parse import quote\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "from pfd_toolkit import LLM, Screener\n",
    "from pfd_toolkit.config import GeneralConfig\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "def ensure_secret(env_name: str) -> str:\n",
    "    if env_name not in os.environ or not os.environ[env_name]:\n",
    "        os.environ[env_name] = getpass(f\"Enter {env_name}: \")\n",
    "    return os.environ[env_name]\n",
    "\n",
    "OPENAI_API_KEY = api_key\n",
    "\n",
    "GITHUB_BASE = \"https://raw.githubusercontent.com/Sam-Osian/PFD-toolkit/open-model-exp\"\n",
    "DATA_URL = f\"{GITHUB_BASE}/ons_replication/{quote('PFD Toolkit--Consensus Comparison.xlsx')}\"\n",
    "SHEET_NAME = \"Consensus annotations\"\n",
    "RESULTS_PATH = NOTEBOOK_DIR / \"model_comparison.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1245de2",
   "metadata": {},
   "source": [
    "## Start Ollama in Colab\n",
    "\n",
    "Install and start the Ollama daemon locally so the open-weight models can be downloaded and served within this runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8503706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Ollama...\n",
      ">>> Installing ollama to /usr/local\n",
      ">>> Downloading Linux amd64 bundle\n",
      "######################################################################## 100.0%\n",
      ">>> Creating ollama user...\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n",
      "Starting ollama serve...\n",
      "Ollama is ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "OLLAMA_PORT = 11434\n",
    "OLLAMA_BASE_URL = f\"http://localhost:{OLLAMA_PORT}/v1\"\n",
    "\n",
    "if not shutil.which(\"ollama\"):\n",
    "    print(\"Installing Ollama...\")\n",
    "    !curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# Start the Ollama server if it isn't already running\n",
    "try:\n",
    "    requests.get(f\"http://localhost:{OLLAMA_PORT}/api/tags\", timeout=2)\n",
    "    print(\"Ollama is already running.\")\n",
    "except Exception:\n",
    "    print(\"Starting ollama serve...\")\n",
    "    ollama_process = subprocess.Popen(\n",
    "        [\"ollama\", \"serve\"],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL,\n",
    "    )\n",
    "    for _ in range(60):\n",
    "        try:\n",
    "            requests.get(f\"http://localhost:{OLLAMA_PORT}/api/tags\", timeout=2)\n",
    "            print(\"Ollama is ready.\")\n",
    "            break\n",
    "        except Exception:\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        raise RuntimeError(\"Ollama failed to start. Check the logs above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47e7e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling mistral-nemo:12b (this may take a few minutes)...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OLLAMA_MODELS = [\n",
    "    {\"name\": \"mistral-nemo:12b\", \"temperature\": 0, \"timeout\": 10**9},\n",
    "    #{\"name\": \"mistral-small:22b\", \"temperature\": 0, \"timeout\": 10**9},\n",
    "    #{\"name\": \"mistral-small:24b\", \"temperature\": 0, \"timeout\": 10**9},\n",
    "]\n",
    "\n",
    "for spec in OLLAMA_MODELS:\n",
    "    print(f\"Pulling {spec['name']} (this may take a few minutes)...\")\n",
    "    subprocess.run([\"ollama\", \"pull\", spec[\"name\"]], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721e1fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to /tmp/pfd_toolkit_consensus.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-141a8c17-1bbf-4f97-9d36-5701686d4b1f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>investigation</th>\n",
       "      <th>circumstances</th>\n",
       "      <th>concerns</th>\n",
       "      <th>consensus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-0452</td>\n",
       "      <td>On 12 August 2022 I commenced an investigation...</td>\n",
       "      <td>Madeleine Savory was 15 years old when they di...</td>\n",
       "      <td>The availability, nationally, of Tier 4 beds i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-0445</td>\n",
       "      <td>On 15 May 2023, one of my assistant coroners, ...</td>\n",
       "      <td>Igor hanged himself in his room at the Depaul ...</td>\n",
       "      <td>On 28 March 2023, Igor refused to get out of t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-0313</td>\n",
       "      <td>On 3 August 2022 I commenced an investigation ...</td>\n",
       "      <td>Allison Aules was referred to the mental healt...</td>\n",
       "      <td>The Inquest identified multiple failings in th...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-0283</td>\n",
       "      <td>On 12 June 2019 I commenced an investigation i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A detailed review of the evidence in this case...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-0146</td>\n",
       "      <td>On 31 August 2022 I opened an investigation to...</td>\n",
       "      <td>On 27 August 2022 Callum Wong was found having...</td>\n",
       "      <td>1. Consideration for exceptions to patient con...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-141a8c17-1bbf-4f97-9d36-5701686d4b1f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-141a8c17-1bbf-4f97-9d36-5701686d4b1f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-141a8c17-1bbf-4f97-9d36-5701686d4b1f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          id                                      investigation  \\\n",
       "0  2023-0452  On 12 August 2022 I commenced an investigation...   \n",
       "1  2023-0445  On 15 May 2023, one of my assistant coroners, ...   \n",
       "2  2023-0313  On 3 August 2022 I commenced an investigation ...   \n",
       "3  2023-0283  On 12 June 2019 I commenced an investigation i...   \n",
       "4  2023-0146  On 31 August 2022 I opened an investigation to...   \n",
       "\n",
       "                                       circumstances  \\\n",
       "0  Madeleine Savory was 15 years old when they di...   \n",
       "1  Igor hanged himself in his room at the Depaul ...   \n",
       "2  Allison Aules was referred to the mental healt...   \n",
       "3                                                NaN   \n",
       "4  On 27 August 2022 Callum Wong was found having...   \n",
       "\n",
       "                                            concerns  consensus  \n",
       "0  The availability, nationally, of Tier 4 beds i...       True  \n",
       "1  On 28 March 2023, Igor refused to get out of t...       True  \n",
       "2  The Inquest identified multiple failings in th...       True  \n",
       "3  A detailed review of the evidence in this case...       True  \n",
       "4  1. Consideration for exceptions to patient con...       True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(tempfile.gettempdir()) / \"pfd_toolkit_consensus.xlsx\"\n",
    "response = requests.get(DATA_URL, timeout=60)\n",
    "response.raise_for_status()\n",
    "data_path.write_bytes(response.content)\n",
    "\n",
    "print(f\"Dataset downloaded to {data_path}\")\n",
    "\n",
    "df = pd.read_excel(data_path, sheet_name=SHEET_NAME)\n",
    "renamed = df.rename(\n",
    "    columns={\n",
    "        \"Ref\": GeneralConfig.COL_ID,\n",
    "        \"Investigation section\": GeneralConfig.COL_INVESTIGATION,\n",
    "        \"Circumstances of death section\": GeneralConfig.COL_CIRCUMSTANCES,\n",
    "        \"Matters of concern section\": GeneralConfig.COL_CONCERNS,\n",
    "        \"Post-consensus verdict: Is this a child suicide case? (Yes or No)\": \"consensus\",\n",
    "    }\n",
    ")\n",
    "\n",
    "reports = renamed[\n",
    "    [\n",
    "        GeneralConfig.COL_ID,\n",
    "        GeneralConfig.COL_INVESTIGATION,\n",
    "        GeneralConfig.COL_CIRCUMSTANCES,\n",
    "        GeneralConfig.COL_CONCERNS,\n",
    "        \"consensus\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "reports[\"consensus\"] = reports[\"consensus\"].astype(str).str.strip().str.lower() == \"yes\"\n",
    "\n",
    "reports.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a774f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_SPECS = [\n",
    "    # OpenAI API models\n",
    "    {\"name\": \"gpt-4.1\", \"temperature\": 0},\n",
    "    {\"name\": \"gpt-4.1-mini\", \"temperature\": 0},\n",
    "    {\"name\": \"gpt-4.1-nano\", \"temperature\": 0},\n",
    "]\n",
    "\n",
    "# Append Ollama-hosted models using the shared base URL and API key\n",
    "MODEL_SPECS += [\n",
    "    {\n",
    "        \"name\": spec[\"name\"],\n",
    "        \"temperature\": spec[\"temperature\"],\n",
    "        \"base_url\": OLLAMA_BASE_URL,\n",
    "        \"api_key\": \"ollama\",\n",
    "        \"timeout\": spec.get(\"timeout\", 20),\n",
    "    }\n",
    "    for spec in OLLAMA_MODELS\n",
    "]\n",
    "\n",
    "user_query = \"\"\"\n",
    "Identify cases where the deceased was aged 18 or younger *clearly at the time of death* **and**\n",
    "the death was due to suicide. If suicide is not explicitly stated, you can use a strict balance of\n",
    "probabilities threshold to determine it as such.\n",
    "\n",
    "Age may not be explicitly stated, but could be implied through references such as\n",
    "recent use of child or adolescent services (e.g. CAMHS), attending school years\n",
    "(e.g. \"Year 10\"), or similar contextual indicators of being under 18 (again, under a\n",
    "strict balance of probabilities threshold).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4795d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping gpt-4.1 (already evaluated)\n",
      "Skipping gpt-4.1-mini (already evaluated)\n",
      "Skipping gpt-4.1-nano (already evaluated)\n",
      "Testing model: mistral-nemo:12b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending requests to the LLM: 100%|██████████| 146/146 [04:49<00:00,  1.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c5bbbb4d-0c6d-48b2-a26e-14efe38ac288\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>0.910959</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mistral-nemo:12b</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5bbbb4d-0c6d-48b2-a26e-14efe38ac288')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c5bbbb4d-0c6d-48b2-a26e-14efe38ac288 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c5bbbb4d-0c6d-48b2-a26e-14efe38ac288');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              model  accuracy  sensitivity  specificity\n",
       "0           gpt-4.1  0.910959     0.897059     0.923077\n",
       "1      gpt-4.1-mini  0.917808     0.911765     0.923077\n",
       "2      gpt-4.1-nano  0.904110     0.941176     0.871795\n",
       "3  mistral-nemo:12b  0.904110     0.838235     0.961538"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_columns = [\"model\", \"accuracy\", \"sensitivity\", \"specificity\"]\n",
    "if RESULTS_PATH.exists():\n",
    "    results_df = pd.read_csv(RESULTS_PATH)\n",
    "else:\n",
    "    results_df = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "completed_models = set(results_df[\"model\"].astype(str))\n",
    "\n",
    "for spec in MODEL_SPECS:\n",
    "    if spec[\"name\"] in completed_models:\n",
    "        print(f\"Skipping {spec['name']} (already evaluated)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Testing model: {spec['name']}\")\n",
    "\n",
    "    llm_kwargs = {\n",
    "        \"api_key\": spec.get(\"api_key\", os.getenv(\"OPENAI_API_KEY\")),\n",
    "        \"max_workers\": 8,\n",
    "        \"model\": spec[\"name\"],\n",
    "        \"seed\": 12345,\n",
    "        \"timeout\": spec.get(\"timeout\", 20),\n",
    "        \"temperature\": 1 if spec[\"name\"].startswith(\"gpt-5\") else spec[\"temperature\"],\n",
    "    }\n",
    "\n",
    "    if \"base_url\" in spec:\n",
    "        llm_kwargs[\"base_url\"] = spec[\"base_url\"]\n",
    "\n",
    "    llm_client = LLM(**llm_kwargs)\n",
    "    screener = Screener(\n",
    "        llm=llm_client,\n",
    "        reports=reports,\n",
    "        include_investigation=True,\n",
    "        include_circumstances=True,\n",
    "        include_concerns=True,\n",
    "    )\n",
    "\n",
    "    classified = screener.screen_reports(\n",
    "        search_query=user_query,\n",
    "        filter_df=False,\n",
    "        result_col_name=\"model_pred\",\n",
    "    )\n",
    "\n",
    "    pred = classified[\"model_pred\"].astype(bool)\n",
    "    truth = classified[\"consensus\"].astype(bool)\n",
    "\n",
    "    tp = (pred & truth).sum()\n",
    "    tn = ((~pred) & (~truth)).sum()\n",
    "    fp = (pred & ~truth).sum()\n",
    "    fn = ((~pred) & truth).sum()\n",
    "\n",
    "    total = tp + tn + fp + fn\n",
    "    accuracy = (tp + tn) / total if total else float(\"nan\")\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) else float(\"nan\")\n",
    "    specificity = tn / (tn + fp) if (tn + fp) else float(\"nan\")\n",
    "\n",
    "    results_df = pd.concat(\n",
    "        [\n",
    "            results_df,\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"model\": spec[\"name\"],\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"sensitivity\": sensitivity,\n",
    "                        \"specificity\": specificity,\n",
    "                    }\n",
    "                ]\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    results_df.to_csv(RESULTS_PATH, index=False)\n",
    "    completed_models.add(spec[\"name\"])\n",
    "\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
