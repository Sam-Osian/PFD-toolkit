{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## John's Task: Categorisation System for PFD Reports\n",
    "\n",
    "### Purpose\n",
    "\n",
    "The goal of this task is to create a `Categoriser` module for PFD Toolkit. This will be a robust way that users can categorise Prevention of Future Death (PFD) reports using our LLM class. The system should support both broad themes and granular sub-categories that help organise the content for research, policy, and analysis.\n",
    "\n",
    "This is probably the most useful and exciting feature of the Toolkit because it will mean researchers no longer have to manually sift through reports to check whether they're relevant to their research goals, which can take months or even years.\n",
    "\n",
    "\n",
    "### Format\n",
    "\n",
    "I would like the user to be able to provide a custom schema in the following format:\n",
    "\n",
    "> ```Theme, Sub-theme, Description/keywords```\n",
    "\n",
    "This schema will guide the LLM in assigning categories.\n",
    "\n",
    "### Mock research question\n",
    "\n",
    "To give this task some direction, here's a mock research question you can work from. This is optional - feel free to choose a different framing if it’s more useful for testing.\n",
    "\n",
    "Your research question is: \n",
    "> **\"*Where* are suicide deaths preventable?\"**\n",
    "\n",
    "The aim of the research question is to understand the specific venues or contexts behind a preventable death by suicide. This aim is important, because it allows policymakers to identify key priorities for where we could change public policy or NHS practice, ultimately saving lives. \n",
    "\n",
    "\n",
    "### Mock schema \n",
    "Below is a mock-up of the schema that you may wish to run. You don’t need to follow this format exactly (e.g. you’ll likely want to use Pydantic), but here’s a structured example of what I’m hoping the schema will support:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"suicide\": {\n",
    "    \"drug_related\": [\n",
    "      \"overdose\",\n",
    "      \"toxicity\",\n",
    "      \"substance_misuse\",\n",
    "      \"medication_error\",\n",
    "      \"intoxication\",\n",
    "      \"polypharmacy\"\n",
    "    ],\n",
    "    \"institutional_settings\": [\n",
    "      \"prison\",\n",
    "      \"police_custody\",\n",
    "      \"mental_health_inpatient\",\n",
    "      \"secure_hospital\",\n",
    "      \"approved_premises\",\n",
    "      \"detention_centre\"\n",
    "    ],\n",
    "    \"community_care_failures\": [\n",
    "      \"missed_referral\",\n",
    "      \"inadequate_risk_assessment\",\n",
    "      \"lack_of_follow_up\",\n",
    "      \"gp_did_not_refer\",\n",
    "      \"mental_health_team_failure\",\n",
    "      \"discharged_without_support\"\n",
    "    ],\n",
    "    \"communication_errors\": [\n",
    "      \"records_not_shared\",\n",
    "      \"poor_handover\",\n",
    "      \"discharge_summary_not_sent\",\n",
    "      \"information_not_passed_on\",\n",
    "      \"care_coordination_failure\"\n",
    "    ],\n",
    "    \"access_to_means\": [\n",
    "      \"ligature_point\",\n",
    "      \"firearm\",\n",
    "      \"railway_access\",\n",
    "      \"jumped_from_height\",\n",
    "      \"chemical_ingestion\",\n",
    "      \"access_to_high_risk_medication\"\n",
    "    ],\n",
    "    \"recent_contact_with_services\": [\n",
    "      \"seen_by_gp\",\n",
    "      \"discharged_from_hospital\",\n",
    "      \"recent_ae_attendance\",\n",
    "      \"under_mental_health_services\",\n",
    "      \"in_care_of_crisis_team\"\n",
    "    ],\n",
    "    \"domestic_or_social_factors\": [\n",
    "      \"domestic_abuse\",\n",
    "      \"relationship_breakdown\",\n",
    "      \"social_isolation\",\n",
    "      \"recent_bereavement\",\n",
    "      \"housing_insecurity\"\n",
    "    ],\n",
    "    \"youth_or_transitional_risk\": [\n",
    "      \"under_25\",\n",
    "      \"child_and_adolescent_services\",\n",
    "      \"transition_to_adult_services\",\n",
    "      \"excluded_from_school\",\n",
    "      \"care_leaver\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Note that above, we only have 1 top-level theme (\"suicide\") with everything contained within it being sub-themes and descriptions.\n",
    "\n",
    "### Further instructions\n",
    "\n",
    "The default LLM model is `gpt-4.1-mini`, which works fantastically well. However, `gpt-4.1-nano` is much cheaper (but often fails to follow instructions). To save on API costs, please use the nano model for development, and the mini model for making sure it actually works.\n",
    "\n",
    "Please implement the following:\n",
    "\n",
    "- The categorisation module should return the original reports DataFrame, with **additional columns** for each theme and sub-theme. Values in these columns should be `\"Yes\"` or `\"No\"` depending on whether the report meets the criteria.\n",
    "  \n",
    "- Add a **boolean parameter** that controls whether a report can be assigned to **multiple themes / sub-themes** or must be assigned to only the most appropriate one.\n",
    "  \n",
    "- Add the **same parameter for sub-themes**, allowing control over single vs. multi-label classification at both levels.\n",
    "\n",
    "- Add Boolean parameters that determine whether certain sections should be fed to the model. For example, `include_circumstances=False` would mean that this section is never fed to the LLM, saving input tokens. The URL, ID, Date, Coroner name, and Receiver should be `False` by default, with the other sections being `True` by default.\n",
    "\n",
    "- Please place all **LLM-specific logic** in the `llm.py` module. Everything else should go in a new `categoriser.py` module. In `llm.py`, you’ll notice how the base prompts and config are structured for the `Cleaner` class — I’d love if you could mirror that for this.\n",
    "\n",
    "- Please ensure that changes made to `llm.py` are non-destructive (i.e. make sure you only 'add' features, not take any functionality away). If you're unsure, please do test on the two `DEMO` notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "### Optional Features, in order of preference (if you have time or feel inclined)\n",
    "\n",
    "- The `LLM` class has a `max_workers` parameter for parallel processing. Your work should ideally use this to speed things up.\n",
    "\n",
    "- Add a Boolean parameter that controls whether the **third tier (description/keywords)** should be treated as **sub-sub-themes** (i.e. distinct columns), or just descriptive phrases to support assignment to the sub-theme level.\n",
    "\n",
    "- If implemented, please apply the same `\"Yes\"/\"No\"` structure for sub-sub-themes. Please also extend your multi- or single-theme assignment parameter to the sub-sub-theme.\n",
    "\n",
    "- Add a Boolean parameter to **automatically include an \"Other / None of the above\"** category at the theme, sub-theme, or sub-sub-theme level as appropriate.\n",
    "\n",
    "---\n",
    "\n",
    "### What you **don't** need to do\n",
    "\n",
    "- You don't need to do any formal evaluation - that's for me to do! It would be good if you could eyeball the outputs though to make sure everything looks right. I can then go from there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data\n",
    "\n",
    "There are two files you'll need for the mock research question.\n",
    "\n",
    "1. `../data/suicide_reports.csv` -- 293 scraped, suicide-specific reports spanning from 1st May 2023 to 1st May 2025.\n",
    "2. `../data/suicide_reports_sample.csv` -- a sample of 50 reports you can use for development to save on token costs.\n",
    "\n",
    "You do not need to run the below blocks; it's just to show where the datasets came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL', 'ID', 'Date', 'CoronerName', 'Area', 'Receiver',\n",
       "       'InvestigationAndInquest', 'CircumstancesOfDeath', 'MattersOfConcern'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('../data/suicide_reports_sample.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How I'd like the API to look \n",
    "\n",
    "This isn't a requirement, just a suggestion! \n",
    "\n",
    "The below code will NOT run because the module hasn't been created yet. It's just a mock-up of what I'm imagining. Notice how it closely resembles the PFDScraper and Cleaner classes for a nice, harmonised user-interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Categoriser' from 'pfd_toolkit' (C:\\Users\\jonat\\Documents\\Python\\pfd-toolkit\\src\\pfd_toolkit\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpfd_toolkit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Categoriser, LLM\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Categoriser' from 'pfd_toolkit' (C:\\Users\\jonat\\Documents\\Python\\pfd-toolkit\\src\\pfd_toolkit\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from pfd_toolkit import Categoriser, LLM\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Get API key\n",
    "load_dotenv(\"api.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set up LLM client\n",
    "llm_client = LLM(api_key=openai_api_key, \n",
    "                 max_workers=30) # Max workers to parallelise Categoriser tasks\n",
    "\n",
    "schema = {...} # Imagine categorisation schema is provided here\n",
    "\n",
    "\n",
    "categoriser = Categoriser(\n",
    "    # Most important:\n",
    "    reports = sample_reports, # Dataframe containing scraped reports\n",
    "    llm = llm_client,\n",
    "    schema = schema,\n",
    "    \n",
    "    # Other desired functionality as optional params\n",
    "    third_tier_as_theme = True, # ...whether to treat the third tier as a sub-sub-theme (True) or just as a description of the sub-theme (False)\n",
    "    multi_assignment = True, # ...whether reports can be assigned to multiple themes and sub-themes (True) or not (False)\n",
    "    include_date = False, # All existing columns need a toggle for whether this should be fed to the model. `include_date` is just one example\n",
    "    other_category = True # Whether to append an other / none of the above category to the themes / sub-themes / sub-sub-themes (if used)\n",
    ")\n",
    "\n",
    "categoriser.reports # Returns DataFrame with additional Yes/No columns for each theme / sub-theme / sub-sub-theme (if using)\n",
    "categoriser.tabulation # Returns a DataFrame with the counts of each theme / sub-theme / sub-sub-theme (if using). I can develop this myself :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
