{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO of response format capabilities\n",
    "As you can see in the below made up example, the LLM is FORCED to produce outputs in the format laid out in the class called Test. It's important that Test inherits from Pydantic's BaseModel, as this is handled internally by the openai SDK and is also used to parse the text json output back into the class. Once you have the output object, you can access the attributes of the object like normal. The use of Typing is enforced by openai, ensuring that a string is always a string, an integer is always an integer, a List is always a list, and a Literal has to be one of the options you give it. This is perfect for ensuring LLM outputs are bulletproof in their conforming to your expected outputs, meaning that they do not break unexpectedly no matter what the input is.\n",
    "\n",
    "The use of Field, from pydantic allows you to add a description property to the attribute. This description is provided to the LLM too, and so are any docstrings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfd_toolkit.llm import LLM\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "load_dotenv()\n",
    "class Test(BaseModel):\n",
    "    \"\"\"An example response format case, this text is seen by the LLM too!\"\"\"\n",
    "    name: str = Field(..., description='The name of the patient')\n",
    "    sibling_ages: List[str] = Field(..., description='The ages of their siblings')\n",
    "    death_reason: str = Field(..., description='A verbose reason for the patients death')\n",
    "    category: Literal['suicide', 'old-age', 'boreddd'] = Field(..., description='Which category the death reason falls into')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.generate(prompt='hi!', response_format=Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test(name='John Doe', sibling_ages=['25', '30', '22'], death_reason='John Doe passed away due to complications arising from a long-term battle with depression, which ultimately led to his decision to take his own life.', category='suicide')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "John Doe passed away due to complications arising from a long-term battle with depression, which ultimately led to his decision to take his own life.\n",
      "['25', '30', '22']\n",
      "suicide\n"
     ]
    }
   ],
   "source": [
    "print(res.name)\n",
    "print(res.death_reason)\n",
    "print(res.sibling_ages)\n",
    "print(res.category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
